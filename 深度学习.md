# 深度学习札记
--------------------------

1. **CNN**卷积网络
   - 神经网络作用：**特征提取**
   - CNN卷积网络：
       - CNN整体架构 ：**输入层** -> **卷积层** ->**非线性激活层**-> **池化层** -> **全连接层**
           1. **输入层** ：输入三维图像，即图像高度、图像宽度、颜色通道数(灰度只有一个通道，RGB图有三个通道)
           2. **卷积层** ：目的是对图像各个区域进行特征提取，最后得到一个**特征图**
               - 对于输入层的图像，利用**卷积核**滑动提取特征，且每个通道分别进卷积核，每个区域最后只对应一个特征值
               - 卷积核主要依赖**权重矩阵**和**偏置项**工作
               - 每个卷积核在每个区域最后对应的特征值等于**每个通道像素值矩阵和卷积核的权重矩阵的内积之和+偏置项**，这其实就是一次线性变换y=wx+b
                    - **卷积核的权重矩阵** ：相当于线性变化中的w，每个卷积核的具体权重由CNN训练过程决定，最开始被随机赋予最小值，不同核具有不同的权重矩阵，同一个卷积核在三个通道中的权重矩阵也不相同，相互独立，各自学习，单次卷积过程，卷积核的权重矩阵不变
                    - **偏置项**：相当于线性变换中的b，随机设定的一个值，目的是调整阈值、提高灵活性、破坏对称型，也会随着CNN训练过程改变
               - 单次卷积，卷积核可以有**多个**，每个卷积核只对应一个特征图，多个卷积核意味着结果生成多个特征图
               - 卷积可以做**多次**，下一次卷积在上一次卷积得到的特征图基础之上
               - 卷积层常用参数：
                   - **滑动步长**：卷积核每次滑动的像素个数，步长越小提取的特征值越多，但是处理速度越慢
                   - **卷积核尺寸**：卷积核权重矩阵的大小，最小的卷积核一般是3*3大小
                   - **边缘填充**：输入图像的像素值矩阵中，越靠近中心的像素值被计算的次数越多，越边缘的像素值越容易被忽略，在原图像外围加上一圈0可以将原来的边界更靠近中心，从而使得每个位置的像素值最最后结果的影响更加公平
                   - **卷积核个数**：每个卷积核对应一个生成的特征图，其权重矩阵各自独立
               - 卷积结果长度/宽度计算公式：**H2 = (H1 - FH + 2P)/S + 1**   
                   - H2:卷积后的长度或宽度
                   - H1:卷积前的长度或宽度
                   - FH:卷积核的长度或宽度
                   - P:边缘厚度
                   - S:步长
           3. **非线性激活层**:
               - 线性函数：满足f(ax+by)=af(x)+bf(y)的函数，函数图像本身为直线
               - 为什么神经网络需要非线性激活函数？
                   - 非线性函数是为了增加神经网络非线性拟合能力，如线性函数y=ax+b，无论给这个函数增加多少次线性变换，都只能得到线性函数，无法得到非线性函数，也就意味着神经网络将无法拟合任何非线性函数，也就几乎没有了存在的意义。
               - 非线性激活函数有哪些性质会导致出现问题？
                   - 如果非线性函数在正负无穷初梯度(可理解为导数)为0被称为**饱和函数**，如果同时梯度最大值较小，则在反向传播过程中会导致梯度消失
                   - 如果非线性激活函数是**非零均值函数**，即输出值的期望不为0，则会导致学习过程中所有参数符号始终一致，使得神经网络不易收敛
               - 常用的非线性激活函数：
                   - **Relu函数(修正线性单元)**：
                       - 公式: Relu = max(0,x)
                       - 当输入为x<0时，输出为0，当输入为x>0时，输出为x，这样对卷积后的特征图中的每一个特征值进行处理，
                       - 优势：非饱和函数，输入值大于零时梯度恒为1，解决回传梯度消失问题；同时计算简单，收敛较快
                       - 缺点：神经元死亡：当输入值小于0时，梯度为0；非零均值函数：影响收敛效果，可使用归一化解决；梯度爆炸：没有上界，梯度随计算累积至超过计算机数值上限，可使用参数初始化解决
                   - **LeakyReLU函数**：
                       - 公式：f(x)=x,(x>0 ); f(x)=ax,(x<=0)，其中a是一个很小的数，但不变
                       - 优势：具备ReLU的优点，，同时减轻神经元死亡的的问题
                       - 缺点：a是一个超参数，不能通过学习改变，但是对训练结果相当重要，使得影响训练结果的不确定因素增加
                   - **Prarametic ReLU函数**
                       - 公式：f(x)=x,(x>0 ); f(x)=ax,(x<=0)，其中a可以随着学习过程改变
                       - 优势：集合了LeakyReLU和ReLU的优势
                       - 缺点：增加模型复杂度与过拟合化风险
                   - **sigmoid函数**：
                       - 公式：f(x)=1/[1+e^(-x)],输出值在0到1之间
                       - 优势：可以直接表示概率，输出是一个平滑的概率分布
                       - 缺点：饱和函数：导致梯度消失；非零均值函数：导致不易收敛
                   - **双曲正切激活函数(Tanh)**：
                       - 公式：f(x)=(e^x - e^(-x))/(e^x + e^(-x))
                       - 优点：零均值函数：输出值以0为中心，使得权重更新时不会偏向任一方，梯度有正有负，有利于改善梯度流
                       - 缺点：饱和函数：当输入值的绝对值非常大时，仍然有梯度消失问题
           4. **池化层** ：目的是将来自于卷积层的特征图压缩(不含任何矩阵运算)
               - **最大池化**：只取所选区域中最大的特征值，特征值越大说明网络认为这个地方的特征越重要（只关注是否有，不关注哪里有）
               - **平均池化**：将所选区域的所有特征值求平均，作为新的特征值，此方法被证明显著弱于最大池化的效果
           5. **全连接层（FC）**：目的是对特征图进行维度上的改变，使用Softmax函数得出每个类别的概率
              1. Softmax函数：
                 1. 公式：
                    - $Softmax(z_i)= \frac{e^{z_i}}{\sum\limits_{j=1}^{K}e^{z_j}}$
                    - 原向量Z每一项包含每个类别得分，经过Softmax函数之后新向量Z中每一项表示每个类别概率值，即置信度
                    - K是向量Z的长度，即类别的数量

        - CNN核心算法：
          1. 梯度下降算法：
             1. 为什么会需要这种算法：
                - 模型训练的过程其实就是网络自行拟合原函数的过程，用众多个样本点作为实际值，每一层卷积核中所进行的线性变换加上非线性激活层的非线性变换，到最后的全连接层时就会出来一个非线性拟合函数，用损失函数通过计算当前拟合的值和每个样本点的实际值之差等手段，衡量当前所拟合函数的质量。神经网络的目的，就是在原始数据集的每一轮训练后不断改变每个卷积核中权重和偏置这两个参数，得到一组最优的参数使得最后的损失函数的值最小，即拟合的效果最佳，而梯度下降算法就是让权重和偏置参数能够朝着让损失函数值变小的方向改变的一种手段。
             2. 损失函数：
                - 衡量预测值和真实值之间差异情况的函数
                - 种类：
                  1. **均方误差（MSE损失函数）：**
                     - 通常用于回归问题，或者一些需要预测连续值的问题，如图像重建和超分辨率问题
                     -  $MSE=\frac{1}{n}\sum\limits_{i=1}^n(Y_i-\hat{Y_i})^2$
                  2. **交叉熵损失（CE损失函数）**
                     1. 此损失函数主要用于目标分类问题
                     2. 拟合的目标结果在于让交叉熵损失函数取得最小值，即让样本属于其真实类的概率最大
                     3. 在二分类和多分类问题中，使用one-hot编码来表示每个样本的真实标签，例如，如果有一个四分类问题，类别为 {A, B, C, D}，那么类别 A 可以被编码为 [1, 0, 0, 0]，类别 B 可以被编码为 [0, 1, 0, 0]，以此类推
                     4. **二分类问题：**
                        - $CE=-\frac{1}{n}\sum\limits_{i=1}^{n}[Y_iln(\hat{Y_i})+(1-Y_i)ln(1-\hat{Y_i})]$
                        - $Y_i$ 表示第i个样品是不是于这个类，是为1，不是为0
                     5. **多分类问题：**
                        - $CE=-\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{K}Y_{ij}\ln(\hat{Y_{ij}})$
                        - $Y_{ij}$ 是第i个样品标签中属于第j类的编码，是第j类就是1，不是就是0；$\hat{Y_{ij}}$ 是第i个样品的第j类的预测概率，由Softmax函数输出的Z向量得出，K是类别数量，n是样本数 
             3. 梯度下降算法：
                1. 概念：
                   - 对于非线性函数 $y=f(x,w,b)$ ,其中w、b分别是权重和偏置，在此处共同影响函数走势，神经网络的目的就是通过学习获得一组最优的w、b值，使得损失函数取得最小值，而对于损失函数 $L(w,b)$来说，其有两个自变量w，b，是一个空间中的二元函数，对于多元函数来说，**负梯度方向**是函数值减小最快的方向，为了让损失函数值以最快速度下降，应当让w、b沿着各自负梯度方向减小，所以每次得出损失函数之后应当按照负梯度方向更新w、b,其中二元函数的梯度向量可以表示为：$∇L = [\frac{∂L}{∂w}, \frac{∂L}{∂b}]$，$L()$关于w、b的的梯度分别是$\frac{∂L}{∂w}$、$\frac{∂L}{∂b}$,以下均用$g$表示。
                2. 公式：
                   - $w = w - α * g$
                   - $b = b - α * g$
                   - 这里的$\alpha$控制梯度下降的步长，是学习率
                3. 针对遇到的问题在原有梯度下降算法算法上做出的改进：
                   1. 内存开销问题：
                      - 更新一次w、b值，需要计算出当前所有样本点的预测值，并交由损失函数计算，如果遇到样本点数量极多的情况，储存这些计算结果需要很大的内存开销，
                      - 解决方法：
                        - **随机梯度下降**:所以针对所有样本点，每次更新只随机且不重复地使用当中的一部分样本点，这样w、b依然可以沿着正确的方向收敛，同时加快计算速度，减轻内存负担
                   2. 损失函数震荡问题：
                      - 损失函数在梯度优化时，参数点可能在一个"山谷"的两侧来回震荡，即每次的梯度优化过于激进，不够平滑，导致损失函数迟迟无法掉入山谷，或者学习率控制的步长没有在后期需要细致优化时变得更小，始终保持不变，造成震荡，无法收敛
                        1. 从梯度角度解决：
                           - 算法：**动量随机梯度下降**：引入上一次的梯度作为“动量”，与这一次的梯度方向做矢量和成为新的梯度方向，这样可以使得每次的优化更加平滑
                           - 公式：
                             - $v=\beta v-\alpha g$
                             - $w=w+v$
                             - $b=b+v$
                             - 其中$v$是新引入的动量，初值是0，$\beta$是动量因子，控制对历史动量的保留程度，是超参数
                             - 此处并没有计算梯度的一阶矩，因为实际上
                        2. 从学习率角度解决：
                           - 网络优化初期，梯度调节需要快速进行，可以大大提高效率，但是后期要想成功收敛，梯度调节的步长必须根据梯度大小等因素自行调节，梯度小时进行细致优化
                           1.  算法1:**Adagrad算法**
                                 - 公式：
                                   - $r=r+g^2$
                                   - $w=w-\frac{\alpha}{\sqrt{r}+\delta}g$
                                   - $b=b-\frac{\alpha}{\sqrt{r}+\delta}g$
                                   - 其中$r$是引入的梯度大小随时间的积累量，即**二阶矩**，在此处使用了指数移动平均(EMA)算法计算二阶矩，即近期数据的权重永远大于早期数据的权重，而且随着新数据到来随时更新，最后也不计算平均值，初值为0，$\delta$是为了防止分母为零引入的极小量
                                 - 优点：如果一个参数的梯度经常很大，那么$r$的值会变大，导致这个参数的学习率下降；反之，如果一个参数的梯度经常很小，那么$r$的值会变小，导致这个参数的学习率上升。这样就可以实现对每个参数的学习率进行自适应调整。
                                 - 不足：，就是由于$r$是一直累积梯度平方的，所以在训练后期，$r$的值可能会变得很大，导致学习率过小，进一步导致训练过早停止。
                           2. 算法2:**RMSprop算法** 
                                - 公式：
                                  - $r=\rho r+(1-\rho)g^2$
                                  - $w=w-\frac{\alpha}{\sqrt{r}+\delta}g$
                                  - $b=b-\frac{\alpha}{\sqrt{r}+\delta}g$
                                - 其中相较于Adagrad算法优势体现在加入了可以手动调节的 $\rho$：衰减率，其为超参数，训练过程中不可人为改变，通常值为0.9或0.99，确定$\rho$ 需要通过交叉验证，他的特点是可以控制优化过程
                        3. 同时从梯度角度和学习率角度：
                           - **Adam算法**
                             - 公式：
                               - $s=\rho _1s+(1-\rho _1)g$
                               - $\hat s=\frac{s}{1-{\rho _1}^t}$
                               - $r=\rho _2r+(1-\rho _2)g^2$
                               - $\hat r=\frac{r}{1-{\rho _2}^t}$
                               - $w=w-\frac{\alpha \hat s}{\sqrt{\hat r}+\delta}$
                               - $b=b-\frac{\alpha \hat s}{\sqrt{\hat r}+\delta}$
                               - $s$ 是自适应动量，继承自动量随机梯度下降算法；$r$ 是引入的梯度随时间积累的量，继承自Adagrad算法；$\rho_1$、$\rho_2$ 是衰减率，继承自RMSprop算法；$\hat s$、$\hat r$ 分别是 $s$ 和$r$ 随迭代过程的修正值
                               - $\rho_1$、$\rho_2$ 衰减率一般设置为0.9或0.99，这样迭代初期 $s$、$r$ 接近于0 ，但是