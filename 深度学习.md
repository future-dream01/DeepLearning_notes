# 深度学习札记
--------------------------

1. **CNN**卷积网络
   - 神经网络作用：**特征提取**
   - CNN卷积网络：
       - CNN整体架构 ：**输入层** >>> **卷积层** >>>**非线性激活层**>>> **池化层** >>>**展平层** >>**全连接层**
           1. **输入层** ：输入三维图像，即图像高度、图像宽度、颜色通道数(灰度只有一个通道，RGB图有三个通道)
           2. **卷积层** ：目的是对图像各个区域进行特征提取，最后得到一个**特征图**
               - 对于输入层的图像，利用**卷积核**滑动提取特征，且每个通道分别进卷积核，每个区域最后只对应一个特征值，卷积核的每次卷积操作都对应着一个神经元，每次的线性变换得出最后的特征值都是一次神经元输出，所以一个卷积核对应多个**神经元**，每个神经元可以对应多个权重矩阵(数量等于上层输入的深度)，只不过在卷积层中这些神经元之间共享参数。
               - 卷积层中神经元数=卷积核数*每个卷积核卷积操作数
               - 卷积核主要依赖**权重矩阵**和**偏置项**工作
               - 每个卷积核在每个区域最后对应的特征值等于**每个通道像素值矩阵和卷积核的权重矩阵的内积之和+偏置项**，这其实就是多个线性变换y=wx+b叠加，可以拟合复杂函非线性函数
                    - **卷积核的维数**：卷积核的维数与输入的数据维数相同，如：输入是一个三通道的彩色图像，那么对应卷积核的深度就必须是3；如果输入的是多维特征图，即多张特征图，则卷积核的维数也应当与之相对应，其中各个维度之间的权重矩阵并不相同，但是同一维度的权重矩阵所有神经元中共享。
                    - **卷积核的权重矩阵** ：相当于线性变化中的w，每个卷积核的具体权重由CNN训练过程决定，最开始被随机赋予最小值，不同核具有不同的权重矩阵，同一个卷积核在三个通道中的权重矩阵也不相同，相互独立，各自学习，单次卷积过程，卷积核的权重矩阵不变
                    - **偏置项**：相当于线性变换中的b，随机设定的一个值，目的是调整阈值、提高灵活性、破坏对称型，也会随着CNN训练过程改变
               - 单次卷积，卷积核可以有**多个**，每个卷积核只对应一个特征图，多个卷积核意味着结果生成多个特征图
               - 卷积可以做**多次**，下一次卷积在上一次卷积得到的特征图基础之上
               - 卷积层常用参数：
                   - **滑动步长**：卷积核每次滑动的像素个数，步长越小提取的特征值越多，但是处理速度越慢
                   - **卷积核尺寸**：卷积核权重矩阵的大小，最小的卷积核一般是3*3大小
                   - **边缘填充**：输入图像的像素值矩阵中，越靠近中心的像素值被计算的次数越多，越边缘的像素值越容易被忽略，在原图像外围加上一圈0可以将原来的边界更靠近中心，从而使得每个位置的像素值最最后结果的影响更加公平
                   - **卷积核个数**：每个卷积核对应一个生成的特征图，其权重矩阵各自独立
               - 卷积结果长度/宽度计算公式：$$H2 = \frac{H1 - FH + 2P}{S} + 1$$ 
                   - H2:卷积后的长度或宽度
                   - H1:卷积前的长度或宽度
                   - FH:卷积核的长度或宽度
                   - P:边缘厚度
                   - S:步长
           3. **非线性激活层**:
               - 线性函数：满足$f(ax+by)=af(x)+bf(y)$的函数，函数图像本身为直线
               - 为什么神经网络需要非线性激活函数？
                   - 非线性函数是为了增加神经网络非线性拟合能力，如线性函数y=ax+b，无论给这个函数增加多少次线性变换，都只能得到线性函数，无法得到非线性函数，也就意味着神经网络将无法拟合任何非线性函数，也就几乎没有了存在的意义。
                   - 然而一旦引入了非线性函数，此处以reLU函数为例，他在神经网络中的作用方式主要有两种：一种是前向传播过程中Relu函数和线性变换的**多层嵌套**：$output = ReLU(w2 * ReLU(w1 * x + b1) + b2)$,这种作用形式可以创造出单尖点的非线性函数，但是显然远远不够，在卷积核中运行内积算法时所以在全连接层中，会出现将这一层中所有神经元输出相加的过程，由于每个神经元的输出与最初的输入都是一个非线性关系，所有非线性函数在这一层**相互叠加**，即出现了 $ReLU(w1*x + b1) + ReLU(w2*x + b2)+……$ 的现象，而这样的相加则直接产生尖点无限多的复杂非线性函数，完全达到拟合所有非线性函数的效果，在CNN中，每个神经元的输出都要套上一个ReLU激活函数，以最大程度提高其非线性函数的拟合度
               - 非线性激活函数有哪些性质会导致出现问题？
                   - 如果非线性函数在正负无穷初梯度(可理解为导数)为0被称为**饱和函数**，如果同时梯度最大值较小，则在反向传播过程中会导致梯度消失
                   - 如果非线性激活函数是**非零均值函数**，即输出值的期望不为0，则会导致学习过程中所有参数符号始终一致，使得神经网络不易收敛
               - 常用的非线性激活函数：
                   - **ReLU函数(线性修正单元)**：
                       - 公式: $$ReLU = max(0,x)$$
                         - 其中当输入为x<0时，输出为0，当输入为x>0时，输出为x，这样对卷积后的特征图中的每一个特征值进行处理，
                       - 优势：非饱和函数，输入值大于零时梯度恒为1，解决回传梯度消失问题；同时函数简单，收敛较快，这一点也使得Relu函数称为卷积网络中使用最多的激活函数
                       - 缺点：神经元死亡：当输入值小于0时，梯度为0；非零均值函数：影响收敛效果，可使用归一化解决；梯度爆炸：没有上界，梯度随计算累积至超过计算机数值上限，可使用参数初始化解决
                   - **LeakyReLU函数**：
                       - $$
                       f(x) = \begin{cases}
                       x & \text{if} x > 0 \\
                       ax & \text{if} x \leq 0 
                       \end{cases}
                       $$
                         - 其中a是一个很小的数，但不变
                       - 优势：具备ReLU的优点，，同时减轻神经元死亡的的问题
                       - 缺点：a是一个超参数，不能通过学习改变，但是对训练结果相当重要，使得影响训练结果的不确定因素增加
                   - **Prarametic ReLU函数**
                       - $$
                       f(x) = \begin{cases}
                       x & \text{if} x > 0 \\
                       ax & \text{if} x \leq 0 
                       \end{cases}
                       $$
                         - 其中a可以随着学习过程改变
                       - 优势：集合了LeakyReLU和ReLU的优势
                       - 缺点：增加模型复杂度与过拟合化风险
                   - **sigmoid函数**：
                       - 公式：$$f(x)=\frac{1}{1+e^{-x}}$$
                         - 输出值在0到1之间
                       - 优势：可以直接表示概率，输出是一个平滑的概率分布
                       - 缺点：饱和函数：导致梯度消失；非零均值函数：导致不易收敛
                   - **双曲正切激活函数(Tanh)**：
                       - 公式：$$f(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}$$
                       - 优点：零均值函数：输出值以0为中心，使得权重更新时不会偏向任一方，梯度有正有负，有利于改善梯度流
                       - 缺点：饱和函数：当输入值的绝对值非常大时，仍然有梯度消失问题
           4. **池化层** ：目的是将来自于卷积层的特征图压缩(不含任何矩阵运算)
               - **最大池化**：只取所选区域中最大的特征值，特征值越大说明网络认为这个地方的特征越重要（只关注是否有，不关注哪里有）
               - **平均池化**：将所选区域的所有特征值求平均，作为新的特征值，此方法被证明显著弱于最大池化的效果
           5. **展平层**：目的是将池化层输出的多维度特征图转变为全连接层输入需要的一维向量
              1. 在一般的卷积神经网络中此过程只是简单的将多位特征图中的特征值拼接成一维向量，并不涉及参数学习和数值的改变
           6. **全连接层（FC）**：(分类任务网络)目的：使用Softmax函数得出样本属于每个类别的概率
               1. **全连接层中的前几层神经元**：
                  1. 池化层的输出特征图经过展平层从二维矩阵变成了一维列向量，每一层中的每个神经元中包含一个一维行向量，存放权重系数，同一层中所有神经元的权重向量合在一起组成了权重系数矩阵，同时还有一个偏置列向量，存放偏置的值，全连接层的线性变换过程就是**全部神经元权重系数行向量组成的矩阵和输入的特征值列向量进行矩阵乘法，然后将每个神经元对应的结果(其实就是每个权重系数分别都乘以列向量每一位上的特征值再相加得到的值，有点像行向量和列向量的内积)再加上偏置矩阵中相应位置的值即可($y=kx+b$)。**线性变换的结果是得到一个列向量(基本的矩阵乘法知识)，作为下一层全连接神经元的输入，以此类推。需要注意的是每一层每个神经元的权重系数行向量长度和这一层输入的列向量长度相等，而每一层的总神经元数量又对应了这一层输出列向量长度
                  2. 经过线性变换得到的列向量还要经过一层激活函数，通过激活函数**嵌套**增强非线性拟合能力，同时内积的方式也做到了通过**叠加**的方式将多个简单非线性函数组合成复杂非线性函数，很类似于卷积层中实际进行的操作
                  3. 不难发现，全连接层中的每一个神经元都与上一层中所有神经元输出均相连，而与此不同的是卷积层中神经元均与上层中的部分神经元相连，全连接层因此得名。
               2. **全连接层中的最后一层神经元**：
                  1. 在分类问题中，softmax函数的输入需要是一个长度与类别数相等行向量，其中向量中的每一项都表示原图像经过一系列操作后的对于每个类别的得分，所以最后一层神经元的个数必须等于总类别数，这样才能保证这一层输出的列向量长度等于类总数，以提供给Softmax函数作为数据源。
                  2. 不难发现，对于全连接层最后一层中的每个神经元，其实都是对之前的所有网络结构中的所有非线性拟合的一个汇总，之前过程中所有的线性变换、激活函数嵌套、激活函数叠加，均汇总到了最后一层的每个神经元上，因此这里代表每个类别的每个神经元的输出都是最后每个类别的拟合结果。
               3. Softmax概率预测函数：
                  1. 公式：
                     - $$Softmax(z_i)= \frac{e^{z_i}}{\sum\limits_{j=1}^{K}e^{z_j}}$$
                     - 原向量Z每一项包含每个类别得分，经过Softmax函数之后新向量Z中每一项表示每个类别概率值，即置信度，K是向量Z的长度，即类别的数量
                  2.  Softmax函数通常用于神经网络的输出层(多数情况是全连接层)，特别是在处理多分类问题时。Softmax函数可以将一组实数转换为**概率分布**，使得每一个数都在0到1之间，并且所有数的和为1。这样，每个数就可以被解释为属于某个类别的概率，最后这个包含该物体对每个类别分别概率的向量被传入交叉熵损失函数(分类问题),至此打通所有前向传播，后续开始反向传播和梯度下降
                  3.  卷积分类任务训练的目的，就是将该样本对应于其实际类别的得分在其对于所有类别的得分中的占比提到最大，也就是使Softmax概率预测函数得出的概率提到100%。

       - CNN核心算法：
          1. 梯度下降算法：
             1. 为什么会需要这种算法：
                - 模型训练的过程其实就是网络自行拟合原函数的过程，用众多个样本点作为实际值，每一层卷积核中所进行的线性变换加上非线性激活层的非线性变换，到最后的全连接层时就会出来一个非线性拟合函数，用损失函数通过计算当前拟合的值和每个样本点的实际值之差等手段，衡量当前所拟合函数的质量。神经网络的目的，就是在原始数据集的每一轮训练后不断改变每个卷积核中权重和偏置这两个参数，得到一组最优的参数使得最后的损失函数的值最小，即拟合的效果最佳，而梯度下降算法就是让权重和偏置参数能够朝着让损失函数值变小的方向改变的一种手段。
             2. 损失函数：
                - 衡量预测值和真实值之间差异情况的函数
                - 种类：
                  1. **均方误差（MSE损失函数）：**
                     - 通常用于回归问题，或者一些需要预测连续值的问题，如图像重建和超分辨率问题
                     -  $$MSE=\frac{1}{n}\sum\limits_{i=1}^n(Y_i-\hat{Y_i})^2$$
                  2. **交叉熵损失（CE损失函数）**
                     1. 此损失函数主要用于目标分类问题
                     2. 拟合的目标结果在于让交叉熵损失函数取得最小值，即让样本属于其真实类的概率最大
                     3. 在二分类和多分类问题中，使用one-hot编码来表示每个样本的真实标签，例如，如果有一个四分类问题，类别为 {A, B, C, D}，那么类别 A 可以被编码为 [1, 0, 0, 0]，类别 B 可以被编码为 [0, 1, 0, 0]，以此类推
                     4. **二分类问题：**
                        - $$CE=-\frac{1}{n}\sum\limits_{i=1}^{n}[Y_iln(\hat{Y_i})+(1-Y_i)ln(1-\hat{Y_i})]$$
                        - $Y_i$ 表示第i个样品是不是于这个类，是为1，不是为0
                     5. **多分类问题：**
                        - $$CE=-\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{K}Y_{ij}\ln(\hat{Y_{ij}})$$
                        - $Y_{ij}$ 是第i个样品标签中属于第j类的编码，是第j类就是1，不是就是0；$\hat{Y_{ij}}$ 是第i个样品的第j类的预测概率，由**Softmax函数输出的Z向量**(牛逼)得出，K是类别数量，n是样本数 
             3. 梯度下降算法：
                1. 概念：
                   - 对于非线性函数 $y=f(x,w,b)$ ,其中w、b分别是权重和偏置，在此处共同影响函数走势，神经网络的目的就是通过学习获得一组最优的w、b值，使得损失函数取得最小值，而对于损失函数 $L(w,b)$来说，其有两个自变量w，b，是一个空间中的二元函数，对于多元函数来说，**负梯度方向**是函数值减小最快的方向，为了让损失函数值以最快速度下降，应当让w、b沿着各自负梯度方向减小，所以每次得出损失函数之后应当按照负梯度方向更新w、b,其中二元函数的梯度向量可以表示为：$∇L = [\frac{∂L}{∂w}, \frac{∂L}{∂b}]$ ，$L()$ 关于w、b的的梯度分别是 $\frac{∂L}{∂w}$、$\frac{∂L}{∂b}$ ,以下均用 $g$ 表示。
                2. 公式：
                   - $$w = w - α * g$$
                   - $$b = b - α * g$$
                   - 这里的$\alpha$控制梯度下降的步长，是学习率
                3. 针对遇到的问题在原有梯度下降算法算法上做出的改进：**其实就是解决梯度下降算法中每一轮$w$、$b$减多少的问题**
                   1. 内存开销问题：
                      - 更新一次w、b值，需要计算出当前所有样本点的预测值，并交由损失函数计算，如果遇到样本点数量极多的情况，储存这些计算结果需要很大的内存开销，
                      - 解决方法：
                        - 算法：**随机梯度下降**:所以针对所有样本点，每次更新只随机且不重复地使用当中的一部分样本点，这样w、b依然可以沿着正确的方向收敛，同时加快计算速度，减轻内存负担
                   2. 损失函数震荡问题：
                      - 损失函数在梯度优化时，参数点可能在一个"山谷"的两侧来回震荡，即每次的梯度优化过于激进，不够平滑，导致损失函数迟迟无法掉入山谷，或者学习率控制的步长没有在后期需要细致优化时变得更小，始终保持不变，造成震荡，无法收敛
                        1. 从梯度角度解决：
                           - 算法：**动量随机梯度下降**：引入上一次的梯度作为“动量”，与这一次的梯度方向做矢量和成为新的梯度方向，这样可以使得每次的优化更加平滑
                           - 公式：
                             - $$v=\beta v-\alpha g$$
                             - $$w=w+v$$
                             - $$b=b+v$$
                             - 其中$v$是新引入的动量，初值是0，$\beta$是动量因子，控制对历史动量的保留程度，是超参数
                             - 此处的动量和一阶矩还是有区别的，动量是是过去梯度的累积，用于帮助优化算法在梯度方向上保持稳定的移动；一阶矩是过去梯度的指数移动平均值，用于平滑优化过程
                        2. 从学习率角度解决：
                           - 网络优化初期，梯度调节需要快速进行，可以大大提高效率，但是后期要想成功收敛，梯度调节的步长必须根据梯度大小等因素自行调节，梯度小时进行细致优化
                           1.  算法1:**Adagrad算法**
                                 - 公式：
                                   - $$r=r+g^2$$
                                   - $$w=w-\frac{\alpha}{\sqrt{r}+\delta}g$$
                                   - $$b=b-\frac{\alpha}{\sqrt{r}+\delta}g$$
                                   - 其中$r$是引入的梯度大小随时间的积累量，即**二阶矩**，在此处使用了指数移动平均(EMA)算法计算二阶矩，即近期数据的权重永远大于早期数据的权重，而且随着新数据到来随时更新，最后也不计算平均值，初值为0，$\delta$是为了防止分母为零引入的极小量
                                 - 优点：如果一个参数的梯度经常很大，那么$r$的值会变大，导致这个参数的学习率下降；反之，如果一个参数的梯度经常很小，那么$r$的值会变小，导致这个参数的学习率上升。这样就可以实现对每个参数的学习率进行自适应调整。
                                 - 不足：就是由于$r$是一直累积梯度平方的，所以在训练后期，$r$的值可能会变得很大，导致学习率过小，进一步导致训练过早停止。
                           2. 算法2:**RMSprop算法** 
                                - 公式：
                                  - $$r=\rho r+(1-\rho)g^2$$
                                  - $$w=w-\frac{\alpha}{\sqrt{r}+\delta}g$$
                                  - $$b=b-\frac{\alpha}{\sqrt{r}+\delta}g$$
                                  - $\rho$：衰减率，其为超参数，训练过程中不可人为改变，通常值为0.9或0.99，确定$\rho$ 需要通过交叉验证
                                  - $r$ ：同样是二阶矩，代表了梯度随时间积累的量
                                - 优点：其中相较于Adagrad算法优势体现在加入了可以手动调节的$\rho$，通过不断减小过去数据在总二阶矩中所占权重，可以解决后期二阶矩不断增大导致的学习率过小的问题
                                - 不足：$r$ 初值过小，
                        3. 同时从梯度角度和学习率角度：
                           - **Adam算法**
                             - 公式：
                               - $$s=\rho _1s+(1-\rho _1)g$$
                               - $$\hat s=\frac{s}{1-{\rho _1}^t}$$
                               - $$r=\rho _2r+(1-\rho _2)g^2$$
                               - $$\hat r=\frac{r}{1-{\rho _2}^t}$$
                               - $$w=w-\frac{\alpha \hat s}{\sqrt{\hat r}+\delta}$$
                               - $$b=b-\frac{\alpha \hat s}{\sqrt{\hat r}+\delta}$$
                               - $s$ 是自适应动量，或者说是一阶矩，继承自动量随机梯度下降算法；$r$ 是引入的梯度随时间积累的量，即二阶矩继承自Adagrad算法；$\rho_1$、$\rho_2$ 是衰减率，继承自RMSprop算法；$\hat s$、$\hat r$ 分别是 $s$ 和$r$ 随迭代过程的修正值
                               - $\rho_1$、$\rho_2$ 衰减率一般设置为0.9或0.99，这表明二阶矩中越新的数据所占权重越大，因为新数据权重始终为(1-$\rho$),但是所有的老数据的权重随数据更新在逐渐减小
                               - 之所以创建$\hat s$、$\hat r$,是因为$s$、$r$ 初值较小，接近于0，不能使用，但是后续两值会回归正常，使用公式则可以将初期的$s$、$r$ 放大，之后随着数据的更新，迭代的进行，分母中的$1-{\rho}^t$ 将逐渐接近于1，即，后期$\hat s$、$\hat r$ 将逐渐等于于$s$、$r$，而此时$s$、$r$的值也随着一阶、二阶矩的积累过程回归正常。
          2. 反向传播算法：(BP算法)
             1. 概念：神经网络中加速计算参数梯度值的方法
             2. 一般的计算各个参数梯度值的方法：
                - **前向传播过程**$$x >>> (w_1,b_1)>>>y_1=w_1x+b_1>>>(w_2,b_2)>>>y_2=w_2y_1+b_2>>>L(y_2,y_{gt})$$ 
                  - 其中，$(w_1,b_1)$、$(w_2,b_2)$ 分别是前后两次线性运算的参数，最后损失函数$L(y_2,y_{gt})$ 中 $y_{gt}$ 是真实值，$y$是计算值
                - **反向传播过程**$$\frac{∂L}{∂b_1}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂y_1}\frac{∂y_1}{∂b_1}=\frac{∂L}{∂y_2}w_2<<<\frac{∂L}{∂w_1}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂y_1}\frac{∂y_1}{∂w_1}=\frac{∂L}{∂y_2}w_2x<<<\frac{∂L}{∂b_2}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂b_2}=\frac{∂L}{∂y_2}<<<\frac{∂L}{∂w_2}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂w_2}=\frac{∂L}{∂y_2}y_1$$ 
                  - 其中每一步需要的量都由前向传播过程已知或由上一步已知
             3. 计算机中模块化加速计算梯度值方法
                - **前向传播过程**$$(x,w_1)>>>u_1=w_1x>>>(u_1,b_1)>>>y_1=u_1+b_1>>>(w_2,y_1)>>>u_2=w_2y_1>>>(u_2,b_2)>>y_2=u_2+b_2>>>L(y_2,y_{gt})$$
                  - 其中与一般计算不同的是这其中引入了单元运算概念，即将所有复杂运算拆解成一个个的简单、步骤高度重合、只是数值发生改变的运算，这样就可以将正向传播和反向传播过程用程序来实现
                - **反向传播过程**$$\frac{∂L}{∂w_1}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂u_2}\frac{∂u_2}{∂y_1}\frac{∂y_1}{∂u_1}\frac{∂u_1}{∂w_1}=\frac{∂L}{∂y_2}w_2x<<<\frac{∂L}{∂b_1}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂u_2}\frac{∂u_2}{∂y_1}\frac{∂y_1}{∂b_1}=\frac{∂L}{∂y_2}w_2<<<\frac{∂L}{∂w_2}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂u_2}\frac{∂u_2}{∂w_2}=\frac{∂L}{∂y_2}y_1<<<\frac{∂L}{∂b_2}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂b_2}=\frac{∂L}{∂y_2}$$
                  - 其中每一步需要的量都由前向传播过程已知或由上一步已知
                - 计算机模块化和计算方法深度学习框架相配合，在每个单元运算中均有定义的正向传播和反向传播函数，给每个神经元之间创造了联系通路，神经元拥有了生命。
          3. 神经网络训练的过程，其实就是**前向传播计算数值**>>>**反向传播算法获取梯度**>>>**梯度下降算法更新参数**


2. 初识yolox
   1. 整体结构
      1. **输入端**
         1. **Mosaic数据增强**
            - 大致过程：四张图片通过随机缩放、随机裁剪、随机排布的方式进行拼接，合成一张图片,这几张图片之间互相填充，填满整个输入图像的每个区域
            - 优点：增加样本的多样性、提高模型对小而密集目标的识别能力、让模型在一个batch中处理更多张图片，提高GPU利用率
         2. **Mixup数据增强**
            - 大致过程：将两张图片上下左右填充之后缩放到输入图片标准大小，然后设置一个叠加系数将两张图片上下叠加，相互融合，使得两张图片中的元素包含检测框也会相互重合
            - 优势：增加样本多样性、引入随机性防止过拟合、实现简单
         3. 需要注意：使用Mosaic和Mixup两种数据增强方式会让ImageNet预训练模型变得失去意义，因为所有数据集都得从头开始训练
      2. **Backbone**
         1. 作用：**提取图像特征**
      3. Neck
      4. Prediction
   