# 深度学习浅思

---
## 先验知识
1. **深度学习的历史**
   1. 深度学习的三次浪潮：
      1. 第一次浪潮，*二十世纪四十年代～六十年代*，控制论的兴起：线性神经元模型初步建立
         1. 1943 年，神经科学家**沃伦·麦卡洛克(Warren McCulloch)**和数学家**沃尔特·皮茨(Walter Pitts)**发表论文《神经活动中内在思想的逻辑演算》，建立了神经元的数学模型，即**MCP 模型**，将神经元的工作过程简化为三个过程：输入信号线性加权，求和，非线性激活（阈值法）
         2. 1957 年，计算机科学家**弗兰克·罗森布拉特(Frank Rosenblatt)**发明**感知机**，这是由两层 MCP 神经元组成的神经网络，第一次将 MCP 用于机器学习，并成功运用**梯度下降**算法，感知机被证明可以收敛。
         3. 1960 年，**伯纳德·维德罗(Bernard Widrow)**和学生**霍夫(Hoff)**发明了**自适应线性单元**(Adaline)和**多层自适应线性单元**(Madaline),Madaline 中包含多个 Adaline，是早期的多层神经网络,可以对输入数据进行二分类，同时使用了**最小均方误差**损失函数和**随机梯度下降算法**更新权重，这极大地引起了科学家对人工神经网络的兴趣，但其本质上仍为线性模型，无法处理异或问题
         4. 1969 年，”神经网络之父“**马文·明斯基(Marvin Minsky)**和**西摩尔·帕普特(Seymour Papert)**共同编写《Perceptrons: an introduction to computational geometry》，证明了单层感知机无法解决线性不可分问题，同时发现了当时神经网络面临的死局：（1）基本感知机无法处理异或回路。（2）复杂多层感知机以当时计算机的计算能力无法完成训练。基本杀死感知机方向，使得深度学习浪潮迎来了第一次大衰退。但是这启发了后续神经网络的发展方向：提高硬件算力、加入更多的层和引入非线性计算。
      2. 第二次浪潮：*二十世纪七十年代～九十年代*，联结主义潮流：基本思想是网络通过将大量计算单元连接在一起可以实现智能行为，此时多层神经网络开始出现，但没有较好的训练方法，也没有足够的训练数据
         1. 1974 年，**保罗·韦博斯(Paul Werbos )**在博士论文《Beyond regression : new tools for prediction and analysis in the behavioral sciences》中首次提出**反向传播**算法，使得训练多层神经网络成为可能。
         2. 1980 年**福岛邦彦(Kunihiko Fukushima)**发明**神经认知机**，成为了后来卷积神经网络的基础
         3. 1983 年，AI 教父**杰弗里·辛顿(Geoffrey Hinton)**发明玻尔兹曼机，为深度学习和无监督学习提供理论基础
         4. 1986 年，深度学习(DeepLearning)一次首次由 Rina Dechter 在论文《LEARNING WHILE SEARCHING IN CONSTRAINT-SATISFACTION-PROBLEMS》中引入机器学习社区，
         5. 1989 年，**杨立昆(Yann LeCun)**在《Backpropagation Applied to Handwritten Zip Code Recognition》中提出一种用反向传播进行更新的卷积神经网络，称为 **LeNet** ，启发了后续深度卷积网络的发展
         6. 20 世纪 90 年代统计学习登场，与之而来的还有**支持向量机**、**核方法**、**图模型**，同时神经网络方面的研究不能满足市场不切实际的要求，深度学习发展浪潮迎来第二次衰退
      3. 第三次浪潮：*二十世纪初至今*，真正的深度学习成为可能：深层神经网络的训练方法和训练所需数据量均得到突破
         1. 2006 年，**辛顿**和同事提出**深度信念网络(DBN)**，将由多层受限玻尔兹曼机构成的 DBN 通过**贪婪逐层预训练**的方式解决了深层网络结构的训练难题，该方法很快被证明在其他网络的训练上同样有效。
         2. 2012 年，**辛顿**的学生**亚历克斯·克里泽夫斯基(Alex Krizhevsky)**，**伊利亚·苏茨凯弗(Ilya Sutskever)** 参加 ImageNet 图像分类竞赛，使用**AlexNet**，花费 5 到 6 天，采用 2 块 NVIDIA GTX 580 3GB GPUs 完成了模型训练并以惊人优势拿下冠军，标志着深度卷积神经网络正式走向大众视野
         3. 2022 年，**OpenAI团队** 发布**GPT-3**，这是一个拥有 1750 亿个参数的深度学习模型，是当时最大的深度学习模型，也是第一个能够生成自然语言的模型，标志着深度学习的第三次浪潮的巅峰
2. **深度学习必须知道的知识**
   1. **batch**: 批次，在卷积网络中通常是以一个批次为单位进入输入层，一个批次通常包含多个样本(图片)，甚至是不同类别的样本，决定一个批次中包含多少张图片的参数是一个超参数，训练前人为规定
   2. **epoch**：周期，一个周期表示所有样本都经过一次前向传播和反向传播，即遍历了一次样本集，周期数决定总共遍历多少次，也是超参数，人为决定
   3. **训练集**：模型前向传播和反向传播直接使用的数据集；**验证集**：训练过程中每一轮训练之后评估当前轮次训练结果的数据集，用来执行早期停止、防止过拟合；**测试集**：模型训练完毕之后用来评估整个模型性能的数据集
   4. TensorRT 加速：对于推理过程，可以将 pytorch 格式的网络转化为 TensorRT 格式的网络，TensorRT 格式通过各种方式（层融合、精度校准、内核优化）提高模型在特定硬件上的推理速度，特别适用于边缘设备上的推理过程，在安装过 TensorRT、torch2trt 后可以将模型转化成.engine 文件，在 yolox 中使用--trt 命令行参数即可使用.engine 文件加速推理
   5. 硬件的算力往往与使用的数据格式相关：
      1. **FP64**：双精度浮点格式，64 位，计量单位**TFLOPS(每秒执行的浮点运算次数 万亿次)**，精度高，范围大，但是计算速度慢，一般用于对于高精度科学计算和工程模拟
      2. **FP32**：标准单精度浮点格式，32 位，计量单位**TFLOPS(每秒执行的浮点运算次数 万亿次)**，在精度和占用的储存空间之间实现了很好的平衡，一般用于图形处理和普通计算任务
      3. **FP16**:半精度浮点格式，16 位，计量单位**TFLOPS**在精度即范围上不及 FP32，但可以减少存储需求和计算时间，常用于加速推理，用于深度学习
      4. **FP32/16**：混合精度，也被称为 **Tensor性能**，计量单位**TFLOPS(每秒执行的浮点运算次数 万亿次)**，即在训练过程中使用 FP32 进行梯度计算，但是在权重更新时使用 FP16，这样可以减少计算时间，但是保持较高的精度，用于深度学习
      5. **Int8**：8 位整数格式 计量单位**TOPS(每秒进行的运算次数 万亿次)**，精度小，范围小，但是在资源受限的边缘计算领域广泛用于运算加速
      6. **TF32**：NVIDIA 推出的浮点格式，32 位，计量单位**TFLOPS**精度与 FP32 相同，但做了优化，可以提高性能，用于深度学习较多
      7. **BF16**：GOOGLE 提出的一种数据格式，16 位，指数位与 FP32 相同，所以表示范围相同，但是尾数位不及 FP32，牺牲精度的同时加速了运算
      8. **Int4**：4 位整数格式，计量单位**TOPS**，精度更小，范围更小，但是在资源受限的边缘计算领域广泛用于运算加速
   6. 深度神经网络的训练过程其实就是**端到端**的学习过程，即，我们只知道输入端和输出端的信息，对于中间的过程我们无从知晓
   7. **迁移学习**（Transfer Learning）和**知识蒸馏**（Knowledge Distillation）：
      1. 迁移学习：是一种机器学习方法，它使得一个在某个任务上训练好的模型能够被重新利用在另一个相关但不同的任务上，这种方法的核心思想是，**即使两个任务不完全相同，它们之间也可能共享一些知识或模式。**通过迁移这些知识，可以加速新任务的学习过程，甚至在数据较少的情况下也能达到较好的性能。迁移学习在深度学习领域尤为重要，因为**深度学习模型通常需要大量的数据和计算资源才能从头开始训练。**
      2. 知识蒸馏：主要目的是将一个大型、复杂的模型（通常称为“教师模型”）的知识转移到一个更小、更高效的模型（称为“学生模型”）
      3. 区别：迁移学习旨在将知识从一个任务转移到另一个任务，常用于处理数据量较小的新任务；知识蒸馏旨在将知识从同一任务中的一个较大模型转移到一个较小模型，用于模型压缩。
   8. **强化学习**：
   9.  深度学习中一般把整个模型从小到大层分为：**神经元**——>**层**——>**块**——>**模型(局部)**——>**模型(整体)**
   10. 深度学习中，张量是数据的基本形式，对于图像数据，其一般格式为[批次数，通道数，高度，宽度]，也就是说输入每个层的数据其实并不是单个图片，而是一整个批次的图像被整合在一个张量中被输入进一个层，这有利于 GPU 进行并行计算，但注意：并行计算并不把同一批次中不同图片的特征混合在同一个层中计算，而是保持独立性，即其实是有数量与批次数相同、相互之间参数的平行层分别计算每一张独立的图片，最后再整合进一个张量中。
   11. 一般的图像处理任务，单次输入的图像形式的数据其实是**三维数据**，因为包含了长度、宽度、通道数三个维度；而自然语言任务的处理中，单次输入的数据其实是**二维数据**，包含 token 数、编码长度两个维度，而一些线性模型中输入的向量形式数据是**一维数据**，如音频处理等
   12. 图像数据的表示方式一般有三种：
       1. 一般的图像处理中：[高度，宽度，通道数]
       2. 深度学习模型中
          1. **channels_last格式**：[批次数，高度，宽度，通道数]，一般在TensorFlow 和 Keras 中使用
          2. **channels_first格式**：[批次数，通道数，高度，宽度]，一般在 Pytorch 中使用
3. **英伟达显卡发展历程**
   1. **Fermi架构**：2010 年推出，英伟达第一款完整的GPU架构，也是世界上第一个通用计算GPU架构，确立了英伟达之后两代架构的发展方向
      1. 特点：使用第三代流处理单元(SM)，个 SM 有 32 个 CUDA 内核
      2. 产品：
         1. GTX400系列
         2. GTX500系列
   2. **Kepler架构**：2012年推出，英伟达第一款专注于节能的微架构
      1. 特点
         1. 减少了流处理单元SM的数量，但每个SM中包含的CUDA核心数从32个激增至192个
         2. 首次引入Boost技术，动态调整核心频率
      2. 产品：
         1. 消费级Geforce 系列：
            1. GTX600系
            2. GTX700系
         2. 图形工作站Quadro系列：
            1. Quadro K2000
            2. Quadro K4000
            3. Quadro K5000
            4. Quadro K6000
         3. 数据中心Tesla系列：
            1. Tesla K20
            2. Tesla K20X
            3. Tesla K40
            4. Tesla K80
   3. **Maxwell架构**：2014年推出，
      1. 特点：将流处理单元升级为SMM，相当于将4个SM单元捆绑在一起，每个SM中包含128个CUDA核心
      2. 产品：
         1. 消费级Geforce 系列
            1. GTX700部分系
            2. GTX900系
         2. 图形工作站Quadro系列：
            1. Quadro M2000
            2. Quadro M4000
            3. Quadro M5000
            4. Quadro M6000
         3. 数据中心Tesla系列：
            1. Tesla M4
            2. Tesla M40
            3. Tesla M60
   4. **Pascal架构**：2016年推出，英伟达初代深度学习架构
      1. 特点：引入NVLink，用于GPU与CPU、GPU与GPU之间的通信，实现多卡互联
      2. 核心规格：
         1. GP100：3840个CUDA核心，60组SM单元
         2. GP102：3584个CUDA核心，28组SM单元
      3. 产品：
         1. 消费级 Geforce 系列：
            1. GTX10系
         2. 图形工作站Quadro系列：
            1. Quadro P1000
            2. Quadro P2000
            3. Quadro p4000
            4. Quadro P5000
            5. Quadro P6000
         3. 数据中心Tesla系列：
            1. Tesla P4
            2. Tesla P40
            3. Tesla P100
               1. CUDA核心数：3584
               2. 性能：
                  1. 基于 PCIe：
                     1. **FP64**：4.7 TFLOPS
                     2. **FP32**：9.3 TFLOPS
                     3. **FP16**：18.7 TFLOPS
                  2. 基于 NVLink：
                     1. **FP64**：5.3 TFLOPS
                     2. **FP32**：10.6 TFLOPS
                     3. **FP16**：21.2 TFLOPS
         4. 高性能计算集群DGX系列：
            1. DGX-P100：8块Tesla P100
   5. **Volta架构**：2017年提出，英伟达成熟的深度学习架构
      1. 特点：引入第一代张量核心**TensorCore**，完全为深度学习中大规模张量运算而设计
      2. 产品：
         1. 消费级Geforce系列
            1. GTX20系
         2. 图形工作站Quadro系列：
            1. Quadro GV100
         3. 数据中心Tesla系列：
            1. Tesla V100
               1. CUDA核心数：5120
               2. 张量核心数：640
               3. 性能
                  1. 使用SXM2接口：
                     1. **FP64**：7.8 TFLOPS
                     2. **FP32**：15.7 TFLOPS
                     3. **Tensor(FP32/16)**：125 TFLOPS
                  2. 使用PCIe接口
                     1. **FP64**：7.0 TFLOPS
                     2. **FP32**：14.0 TFLOPS
                     3. **Tensor(FP32/16)**：112 TFLOPS
            2. Tesla V100S
               1. **FP64**：8.2 TFLOPS
               2. **FP32**：16.4 TFLOPS
               3. **Tensor(FP32/16)**：130 TFLOPS
         4. 高性能计算集群DGX系列：
            1. DGX-V100：8块Tesla V100
   6. **Turing架构**：2018年提出，2006年CUDA引入以来最大的性能飞跃，首次支持光线追踪
      1. 特点：
         1. 引入光追核心RTCore
         2. 引入第二代张量核心TensorCore
      2. 产品：
         1. 消费级Geforce系列
            1. GTX16系
            2. GTX20系
         2. 图形工作站Quadro系列：
            1. Quadro RTX3000
            2. Quadro RTX4000
            3. Quadro RTX5000
            4. Quadro RTX6000
            5. Quadro RTX8000
         3. 数据中心Tesla系列：
            1. Tesla T4
            2. Tesla T10
            3. Tesla T40
   7. **Ampere架构**：2020年提出，英伟达第一款支持PCIe 4.0的架构
      1. 特点：
         1. 引入第三代张量核心TensorCore
         2. 引入第二代光追核心RTCore
      2. 产品：
         1. 消费级Geforce系列
            1. RTX30系
               1. 核心规格：
                  1. GA102
                  2. GA104
                  3. GA106
         2. 图形工作站Quadro系列：
            1. Quadro RTX A3000  
            2. Quadro RTX A4000
            3. Quadro RTX A5000
            4. Quadro RTX A6000
         3. 数据中心Tesla系列：
            1. Tesla A10
            2. Tesla A40
            3. Tesla A100
   8. **Ada lovelace架构**：2022 年提出，只用于消费级 Geforce 系列
      1. 特点：
         1. 第四代TensorCore
         2. 第三代RTCore
      2. 产品：
         1. 消费级 Geforce 系列：
            1. RTX 40系
               1. 核心规格：
                  1. AD102：
                     1. GeForce RTX 4090
                        1. **FP32**：83.78 TFLOPS
                        2. **FP16**：330 TFLOPS（使用 Tensor Core）
                        3. **Int8**：1,321 TOPS（使用 Tensor Core）
                  2. AD103：
                     1. GeForce RTX 4080
                        1. **FP32**：49.76 TFLOPS
                        2. **FP16**：99.53 TFLOPS（使用 Tensor Core）
                        3. **Int8**：780 TOPS（使用 Tensor Core）
                     2. GeForce RTX 4070 Ti Super
                        1. **FP32**：
                        2. **FP16**：
                        3. **Int8**：
                     3. GeForce RTX 4080 Super
                        1. **FP32**：
                        2. **FP16**：
                        3. **Int8**：
                  3. AD104：
                     1. GeForce RTX 4070 Ti
                        1. **FP32**：40.09 TFLOPS
                        2. **FP16**：80.18 TFLOPS（使用 Tensor Core）
                        3. **Int8**：641.4 TOPS（使用 Tensor Core）
                     2. GeForce RTX 4070super
                        1. **FP32**：
                        2. **FP16**：
                        3. **Int8**：
                     3. GeForce RTX 4070
                        1. **FP32**：
                        2. **FP16**：
                        3. **Int8**：
                  4. AD106：
                     1. GeForce RTX 4060 Ti(8G)
                        1. **FP32**：22.02 TFLOPS
                        2. **FP16**：
                        3. **Int8**：
                     2. GeForce RTX 4060 Ti(16G)
                        1. **FP32**：
                        2. **FP16**：
                        3. **Int8**：
                  5. AD107:
                     1. GeForce RTX 4050
                        1. **FP32**：
                        2. **FP16**：
                        3. **Int8**：
   9. **Hopper架构**：2022年提出，只用于数据中心 Tesla 系列和图形工作站 Quadro 系列
      1. 特点：
         1. 引入第四代张量核心TensorCore
         2. 引入第三代光追核心RTCore
      2. 产品：
         1. 图形工作站Quadro系列：
            1. Quadro RTX H3000
            2. Quadro RTX H4000
            3. Quadro RTX H5000
            4. Quadro RTX H6000
         2. 数据中心Tesla系列：
            1. Tesla H10
            2. Tesla H40
            3. Tesla H100
            4. Tesla H200
         3. 高性能计算集群DGX系列：
            1. DGX-H100:8块Tesla H100
            2. DGX-H200:8块Tesla H200
   10. **Blackwell 架构**：2024 年发布，AI 核弹
       1.  特点：
           1.  2080 亿个晶体管
           2.  第二代 Transformer 引擎
       2.  产品：
           1. 数据中心 Tesla 系列：
               1.  Tesla B100
               2.  Tesla B200
           2. 超级芯片：
              1. GB200：一颗 Grace CPU 和 2 颗 Tesla B200
           3. 高性能计算集群 DGX 系列：
               1.  DGX-SuperPOD：36 颗GB200

---
## 经典网络结构
1. **深度学习模型性能的衡量与性能优化**：
   1. 关于模型性能的有关概念：
      1. 宏观概念：
         1. **泛化能力**：是指机器学习模型对未见过的新数据（即不包含在训练集中的数据）的处理能力，这意味着模型在训练集上学习到了正确的规律，这些规律在新数据上依然有用；
         2. **过拟合**：模型过度学习了训练数据中的特性，包括噪声和非代表性的特征，导致其泛化能力下降，使得其在训练集以外的数据上表现较差；
         3. **如何提高模型的泛化能力**：
         4. 数据增强\*：通过增加训练数据的多样性，例如通过旋转、缩放、裁剪或颜色调整来扩展图像数据集
         5. 正则化：使用如 L1 或 L2 正则化来限制模型复杂度，通过增额外的惩罚项或约束减少过拟合的风险:
            1. **L1 正则化(Lasso)**：在损失函数中加入权重的绝对值之和，使得模型趋向于产生稀疏的权重矩阵，即很多对目标的影响作用较小的权重值变成 0，进行了特征选择：$$L1_{loss}=\lambda\sum_{i}|w_i|$$
            2. **L2 正则化(Ridge)**：在损失函数中加入权重的平方和，使得权重倾向于减小，但是不至于减小为 0：$$L2_{loss}=\lambda\sum_{i}w_i^2$$
            3. **Dropout**:在训练过程中随机丢弃一部分神经元，即按照一定比例(如 0.5)将一些神经元的输出设为 0，防止神经元之间的共适应性
         6. 交叉验证：使用交叉验证来评估模型在新数据上的表现
         7. 早停：在训练过程中，一旦在验证集上的性能开始下降，即停止训练，以防过拟合
         8. 简化模型结构：减少模型的复杂性，例如减少层数或参数数量，以避免学习过于复杂的模式
         9. 集成方法：如随机森林或梯度提升机等集成学习方法，可以通过组合多个模型来提高泛化能力
      2. 具体概念和性能图：
         1. 目标分类：
            1. 正类、负类：对于一个二分类模型来说，正类和负类分别就是这两个类别；对于一个多分类；对于一个多分类模型来说，通常有多少个类别，就有多少组正类和负类，正负类是相对单个类来说，比如总共有 1、2、3、4、5 类，当我研究 1 类时，1 是我感兴趣的类，故是正类，2、3、4、5 均是负类
            2. TP、TN、FP、FN：
               1. TP (**True Positives**):真正类，正确地将正类预测为正类
               2. FP (**False Positives**):假正类，错误地将负类预测为正类
               3. TN (**True Negative**):真负类，正确地将负类预测为负类
               4. FN (**False Negative**):假负类，错误地将正类预测为负类
               5. 记忆方法：前面的**T、F**表示分类是正确的还是错误地；后面的**P、N**表示分类的结果是正类还是负类
            3. 准确率、精准率、召回率：
               1. 准确率(Accuracy)：表示正确分类的样本数和总样本数之比 $$Accuracy=\frac{TP+TN}{TP+FP+TN+FN}$$
               2. 查准率(精准率)(Precision)：（**被找出来的准不准**）表示正确分类为正类的样本数与所有被分类为正类的样本数之比 $$Precision=\frac{TP}{TP+FP}$$
               3. 查全率(召回率)(真正率)(Recall)：（**被找出来的是不是全的**）表示被正确分类为正类的样本数与所有实际为正类的样本数之比 $$Recall=\frac{TP}{TP+FN}$$
               4. 假正率(False Positive Rate)：在所有实际为负的样本中，被错误地预测为正的比率$$FPR=\frac{FP}{FP+TN}$$
         2. 目标检测：
            1. 正类、负类：对于目标分类来说，不管研究的是哪一个类别所有出现的预测框都属于正类，所有没有出现的预测框都属于负类，但是因为无法显示，所以一般不考虑负类
            2. TP、TN、FP、FN：
            3. TP (**True Positives**):与真值框的交并比值大于 IOU 阈值的预测框
            4. FP (**False Positives**):于真值框的交并比值小于 IOU 阈值的预测框
            5. 准确率、精准率、召回率：
               1. 准确率(Accuracy)：
               2. 查准率(精准率)(Precision)：在设定的分类阈值 $\theta$ 下，计算所有置信度大于分类阈值的$TP_{>\theta}$、$FP_{>\theta}$， $$Precision=\frac{TP_{>\theta}}{TP_{>\theta}+FP_{>\theta}}$$
               3. 查全率(召回率)(真正率)(Recall)：在设置的分类阈值$\theta$下，计算所有置信度大于阈值的$TP_{>\theta}$ $$Recall=\frac{TP_{>\theta}}{TP+FP}$$
         3. 各种性能曲线：
            1. **ROC 曲线**(接受者操作特征曲线)：
               1. 衡量的是在不同**分类阈值**下模型的**召回率**和**假正率**之间的关系
                  1. 分类阈值：模型在决定一个目标属不属于某个类的时候，会有一个阈值，决定当概率大于多少时就判定为该类
               2. 其曲线面积 AUC 与模型性能成正比，曲线越接近左上角，说明模型在保持低假正率同时实现了高召回率，则性能越佳
            2. **P-R 曲线**(精确率-召回率曲线)：
               1. 衡量的是在不同分类阈值下，**精确度**和**召回率**的关系
               2. 曲线面积越大，表示模型在保持高精确度的同时也能保持较高的召回率
   2. 关于**模型性能**的提高方法：
      1. 模型欠拟合：
         1. 从超参数角度
         2. 从模型结构角度
            1. 从数据处理角度：
            2. 从损失函数角度
      2. 模型过拟合：
         1. 从超参数角度
            1. 从模型结构角度
               1. 从数据处理角度：
               2. 从损失函数角度
2. **CNN**卷积网络
   - CNN 整体架构 ：**输入层** >>> **卷积层** >>>**批量归一化层**>>>**非线性激活层**>>> **池化层** >>>**展平层** >>**全连接层**
     1. **输入层** ：输入四维张量，即(**批次数，通道数，图像高度，图像宽度**)(灰度只有一个通道，RGB 图有三个通道)
        - 输入层的图片大小必须统一，例如 yolov5 默认的输入图片大小是 640\*640，如果遇到大小不相同的情况，则会先按照长宽比进行缩放，使得短边长度等于 640，然后再对图片空白区域进行填充，一般填充黑色，这中处理方案的好处在于保持原始图片的长宽比，不会使得图像被拉伸变形
        - 输入层通常是一个 batch，即一个批次，包含很多张图片甚至很多个类别的图片，但是这些图片是**分别、独立**进入后面的所有层，而不是同时进入，所有图片的汇总发生在损失函数计算时的每个图片损失值的求和
     2. **卷积层** ：目的是对图像各个区域进行特征提取，最后得到一个或多个**特征图**
        - 对于输入层的图像，利用**卷积核**滑动提取特征，且每个通道分别进卷积核，每个区域最后只对应一个特征值，卷积核的每次卷积操作都对应着一个神经元，每次的仿射变换得出最后的特征值都是一次神经元输出，所以一个卷积核对应多个**神经元**，每个神经元可以对应多个权重矩阵(数量等于上层输入的深度)，只不过在卷积层中这些神经元之间共享参数。
        - 卷积核:
          1. 卷积核主要依赖**权重矩阵**和**偏置项**工作
             - 每个卷积核在每个区域最后对应的特征值等于**每个通道像素值矩阵和卷积核的权重矩阵的内积之和+偏置项**，这其实就是多个仿射变换(线性变换+平移变换)y=wx+b 叠加。
             - **卷积核的权重矩阵** ：相当于仿射变换中的 w，每个卷积核的具体权重由 CNN 训练过程决定，最开始被随机赋值，不同核具有不同的权重矩阵，同一个卷积核在三个通道中的权重矩阵也不相同，相互独立，各自学习，卷积核前向传播的过程，卷积核的权重矩阵不变
             - **偏置项**：相当于仿射变换中的 b，随机设定的一个值，目的是调整阈值、提高灵活性、破坏对称型，也会随着 CNN 训练过程改变
          2. **卷积核的深度**：卷积核的深度与输入的数据深度相同，如：输入是一个三通道的彩色图像，那么对应卷积核的深度就必须是 3；如果输入的是多维特征图，即多张特征图，则卷积核的深度也应当与之相对应，其中各个维度之间的权重矩阵并不相同，但是**同一通道的权重矩阵所有神经元中共享**。
          3. **卷积核的个数**：一个卷积层中卷积核可以有多个，一个卷积核对应一个生成的特征图，卷积核的个数和最后特征图的深度相同
          4. **卷积核的大小**:同一个卷积层中的所有卷积核大小相同
          5. 卷积可以做**多次**，下一次卷积在上一次卷积得到的特征图基础之上
        - 卷积层常用参数：
          1. **滑动步长**：卷积核每次滑动的像素个数，步长越小提取的特征值越多，但是处理速度越慢
          2. **卷积核尺寸**：卷积核权重矩阵的大小，最小的卷积核一般是 3\*3 大小
          3. **边缘填充**：输入图像的像素值矩阵中，越靠近中心的像素值被计算的次数越多，越边缘的像素值越容易被忽略，在原图像外围加上一圈 0 可以将原来的边界更靠近中心，从而使得每个位置的像素值最最后结果的影响更加公平
          4. **卷积核个数**：每个卷积核对应一个生成的特征图，其权重矩阵各自独立
        - 卷积结果长度/宽度计算公式：$$H2 = \frac{H1 - FH + 2P}{S} + 1$$
          - H2:卷积后的长度或宽度
          - H1:卷积前的长度或宽度
          - FH:卷积核的长度或宽度
          - P:边缘厚度
          - S:步长
     3. **批量归一化层**：目的是使得每一层的输入都有一个相似分布的输入，防止一次正向传播和反向传播之后，参数更新使得靠近输出层的区域神经元的输入因为之前所有神经元所有输出抖动的累积发生剧烈抖动，导致损失函数难以收敛
        1. 实现过程：
           1. 对于此批次所有样本(形状为[N,C,H,W])的同一个**通道**，计算这些通道内所有特征值的均值：$$\mu =\frac{1}{H\times W \times N}\sum \limits_{i=1}^{H\times W \times N}x_i$$ 其中$x_i$是每个特征值
           2. 然后计算这些数值的方差：$$\sigma^2=\frac{1}{H\times W \times N}\sum\limits_{i=1}^{H\times W \times N}(x_i-\mu)^2$$
           3. 然后对每个$x_i$元素标准化：$${x_i}^{'}=\frac{x_i-\mu}{\sqrt{\sigma^2+\delta}}$$ 其中$\delta$是无穷小量，防止分母变成 0
           4. 然后对每个${x_i}^{'}$进行缩放、偏移操作: $$y_i= \gamma*{x_i}^{'}+\beta$$ 其中$\gamma$：缩放参数、$\beta$：偏移参数 是可学习参数
        2. 批量归一化操作中，计算一次均值和方差实际上是使用了一整个批次(顾名思义)中**所有样本的同一通道**中的所有特征值，这样其实并没有将多个样本的信息混合在一起，因为批量归一化操作只是改变了数据的分布，使其更加统一、均匀，具有相同的均值和方差，并没有改变每个样本每个数据之间相对的特征
     4. **非线性激活层**:增加网络对非线性函数的拟合能力
        - 线性函数：满足$f(ax+by)=af(x)+bf(y)$的函数，函数图像本身为直线
        - 为什么神经网络需要非线性激活函数？
          - 非线性函数是为了增加神经网络非线性拟合能力，如线性函数 y=ax+b，无论给这个函数增加多少次仿射变换，都只能得到线性函数，无法得到非线性函数，也就意味着神经网络将无法拟合任何非线性函数，也就几乎没有了存在的意义。
          - 然而一旦引入了非线性函数，此处以 reLU 函数为例，他在神经网络中的作用方式主要有两种：一种是前向传播过程中 Relu 函数和仿射变换的**多层嵌套**：$output = ReLU(w2 * ReLU(w1 * x + b1) + b2)$,这种作用形式可以创造出单尖点的非线性函数，但是显然远远不够，在卷积核中运行内积算法时所以在全连接层中，会出现将这一层中所有神经元输出相加的过程，由于每个神经元的输出与最初的输入都是一个非线性关系，所有非线性函数在这一层**相互叠加**，即出现了 $ReLU(w1*x + b1) + ReLU(w2*x + b2)+……$ 的现象，而这样的相加则直接产生尖点无限多的复杂非线性函数，完全达到拟合所有非线性函数的效果，在 CNN 中，每个神经元的输出都要套上一个 ReLU 激活函数，以最大程度提高其非线性函数的拟合度
        - 非线性激活函数有哪些性质会导致出现问题？
          - 如果非线性函数在正负无穷初梯度(可理解为导数)为 0 被称为**饱和函数**，如果同时梯度最大值较小，则在反向传播过程中会导致梯度消失
          - 如果非线性激活函数是**非零均值函数**，即输出值的期望不为 0，则会导致学习过程中所有参数符号始终一致，使得神经网络不易收敛
        - 常用的非线性激活函数：
          - **ReLU 函数(线性修正单元)**：
            - 公式: $$ReLU = max(0,x)$$
              - 其中当输入为 x<=0 时，输出为 0，当输入为 x>0 时，输出为 x，这样对卷积后的特征图中的每一个特征值进行处理，
            - 优势：非饱和函数，输入值大于零时梯度恒为 1，解决回传梯度消失问题；同时函数简单，收敛较快，这一点也使得 Relu 函数称为卷积网络中使用最多的激活函数
            - 缺点：神经元死亡：当输入值小于 0 时，梯度为 0；非零均值函数：影响收敛效果，可使用归一化解决；梯度爆炸：没有上界，梯度随计算累积至超过计算机数值上限，可使用参数初始化解决
          - **LeakyReLU 函数**：
            - $$
              f(x) = \begin{cases}
              x & \text{if} x > 0 \\
              ax & \text{if} x \leq 0
              \end{cases}
              $$
            - 其中a是一个很小的数，但不变
            - 优势：具备ReLU的优点，，同时减轻神经元死亡的的问题
            - 缺点：a是一个超参数，不能通过学习改变，但是对训练结果相当重要，使得影响训练结果的不确定因素增加
          - **Prarametic ReLU 函数**
            - $$
              f(x) = \begin{cases}
              x & \text{if} x > 0 \\
              ax & \text{if} x \leq 0
              \end{cases}
              $$
              - 其中a可以随着学习过程改变
            - 优势：集合了LeakyReLU和ReLU的优势
            - 缺点：增加模型复杂度与过拟合化风险
          - **sigmoid 函数**：
            - 公式：$$f(x)=\frac{1}{1+e^{-x}}$$
              - 输出值在 0 到 1 之间
            - 优势：可以直接表示概率，输出是一个平滑的概率分布
            - 缺点：饱和函数：导致梯度消失；非零均值函数：导致不易收敛
          - **SiLU 函数**：
            - 公式：$$SiLU=x*\frac{1}{1+e^{-x}}$$
            - 将特征值和经过 sigmoid 函数之后得到的值相乘来引入非线性，非常类似**特征重塑**操作，给与激活函数动态调整特征值所占权重的能力
          - **双曲正切激活函数(Tanh)**：
            - 公式：$$f(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}$$
            - 优点：零均值函数：输出值以 0 为中心，使得权重更新时不会偏向任一方，梯度有正有负，有利于改善梯度流
            - 缺点：饱和函数：当输入值的绝对值非常大时，仍然有梯度消失问题
     5. **池化层** ：目的是将来自于卷积层的特征图压缩(不含任何矩阵运算)
        - **最大池化**：只取所选区域中最大的特征值，特征值越大说明网络认为这个地方的特征越重要（只关注是否有，不关注哪里有）
        - **平均池化**：将所选区域的所有特征值求平均，作为新的特征值，此方法被证明显著弱于最大池化的效果
     6. **展平层**：目的是将池化层输出的多维度特征图转变为全连接层输入需要的一维向量
        1. 在一般的卷积神经网络中此过程只是简单的将多位特征图中的特征值拼接成一维向量，并不涉及参数学习和数值的改变
     7. **全连接层（FC）**：(分类任务网络)目的：使用 Softmax 函数得出样本属于每个类别的概率
        1. **全连接层中的前几层神经元**：
           1. 池化层的输出特征图经过展平层从二维矩阵变成了一维列向量，每一层中的每个神经元中包含一个一维行向量，存放权重系数，同一层中所有神经元的权重向量合在一起组成了权重系数矩阵，同时还有一个偏置列向量，存放偏置的值，全连接层的仿射变换过程就是**全部神经元权重系数行向量组成的矩阵和输入的特征值列向量进行矩阵乘法，然后将每个神经元对应的结果(其实就是每个权重系数分别都乘以列向量每一位上的特征值再相加得到的值，有点像行向量和列向量的内积)再加上偏置矩阵中相应位置的值即可($y=kx+b$)。**仿射变换的结果是得到一个列向量(基本的矩阵乘法知识)，作为下一层全连接神经元的输入，以此类推。需要注意的是每一层每个神经元的权重系数行向量长度和这一层输入的列向量长度相等，而每一层的总神经元数量又对应了这一层输出列向量长度
           2. 经过仿射变换得到的列向量还要经过一层激活函数，通过激活函数**嵌套**增强非线性拟合能力，同时内积的方式也做到了通过**叠加**的方式将多个简单非线性函数组合成复杂非线性函数，很类似于卷积层中实际进行的操作
           3. 不难发现，全连接层中的每一个神经元都与上一层中所有神经元输出均相连，而与此不同的是卷积层中神经元均与上层中的部分神经元相连，全连接层因此得名。
        2. **全连接层中的最后一层神经元**：
           1. 在分类问题中，softmax 函数的输入需要是一个长度与类别数相等的向量，其中向量中的每一项都表示原图像经过一系列操作后的对于每个类别的得分，所以最后一层神经元的个数必须等于总类别数，这样才能保证这一层输出的列向量长度等于类总数，以提供给 Softmax 函数作为数据源。
           2. 不难发现，对于全连接层最后一层中的每个神经元，其实都是对之前的所有网络结构中的所有非线性拟合的一个汇总，之前过程中所有的仿射变换、激活函数嵌套、激活函数叠加，均汇总到了最后一层的每个神经元上，因此这里代表每个类别的每个神经元的输出都是最后每个类别的拟合结果。
        3. Softmax 概率预测函数：
           1. 作用：将每个类别的得分转换为概率，所有类别概率之和为 1
           2. 公式：
              - $$Softmax(z_i)= \frac{e^{z_i}}{\sum\limits_{j=1}^{K}e^{z_j}}$$
              - 原向量 Z 每一项包含每个类别得分，经过 Softmax 函数之后新向量 Z 中每一项表示每个类别概率值，即置信度，K 是向量 Z 的长度，即类别的数量
           3. Softmax 函数通常用于神经网络的输出层(多数情况是全连接层)，特别是在处理多分类问题时。Softmax 函数可以将一组实数转换为**概率分布**，使得每一个数都在 0 到 1 之间，并且所有数的和为 1。这样，每个数就可以被解释为属于某个类别的概率，最后这个包含该物体对每个类别分别概率的向量被传入交叉熵损失函数(分类问题),至此打通所有前向传播，后续开始反向传播和梯度下降
           4. 卷积分类任务训练的目的，就是将该样本对应于其实际类别的得分在其对于所有类别的得分中的占比提到最大，也就是使 Softmax 概率预测函数得出的概率提到 100%。
   - CNN 核心算法：
        1. 梯度下降算法：
           1. 为什么会需要这种算法：
              - 模型训练的过程其实就是网络自行拟合原函数的过程，用众多个样本点作为实际值，每一层卷积核中所进行的仿射变换加上非线性激活层的非线性变换，到最后的全连接层时就会出来一个非线性拟合函数，用损失函数通过计算当前拟合的值和每个样本点的实际值之差等手段，衡量当前所拟合函数的质量。神经网络的目的，就是在原始数据集的每一轮训练后不断改变每个卷积核中权重和偏置这两个参数，得到一组最优的参数使得最后的损失函数的值最小，即拟合的效果最佳，而梯度下降算法就是让权重和偏置参数能够朝着让损失函数值变小的方向改变的一种手段。
           2. 损失函数：
              - 衡量预测值和真实值之间差异情况的函数
              - 种类：
                1. **最小绝对误差(曼哈顿损失)(L1 损失):**
                   - 公式：$$L1=\sum_{i=1}^n |Y_i-\hat{Y_i}|$$
                   - 特点：对所有大小的误差都给予相同的权重，对异常值不敏感
                2. **均方误差(MSE 损失函数)(L2 损失)：**
                   - 通常用于回归问题，或者一些需要预测连续值的问题，如图像重建和超分辨率问题
                   - 公式：$$MSE=\frac{1}{n}\sum\limits_{i=1}^n(Y_i-\hat{Y_i})^2$$
                   - 特点：因为对损失值加平方，所以对更大的误差赋予更大的损失，意味着模型更加倾向于避免大的误差，对异常值更敏感
                3. **交叉熵损失（CE 损失函数）**
                   1. 此损失函数主要用于目标分类问题
                   2. 拟合的目标结果在于让交叉熵损失函数取得最小值，即让样本属于其真实类的概率最大
                   3. 在二分类和多分类问题中，使用 one-hot 编码来表示每个样本的真实标签，例如，如果有一个四分类问题，类别为 {A, B, C, D}，那么类别 A 可以被编码为 [1, 0, 0, 0]，类别 B 可以被编码为 [0, 1, 0, 0]，以此类推
                   4. **二分类问题：**
                      - $$CE=-\frac{1}{n}\sum\limits_{i=1}^{n}[Y_iln(\hat{Y_i})+(1-Y_i)ln(1-\hat{Y_i})]$$
                      - $Y_i$ 表示第 i 个样品是不是于这个类，是为 1，不是为 0，$\hat{Y_i}$ 表示属于这个类的预测概率
                      - 二元交叉熵函数前通常跟 sigmoid 函数，来将类别分数转化为 0~1 之间的概率
                      - 二元交叉熵函数同样能用来处理多类别分类问题，即，将一个 N 类分类问题视作 N 个二分类问题，在每一个类别的判断中都使用一个二元交叉熵损失函数，这样每个类别的概率互不影响，意味着可以做对一个目标的多分类问题，即，一个目标可以同时属于很多个类别。
                   5. **多分类问题：**
                      - $$CE=-\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{K}Y_{ij}\ln(\hat{Y_{ij}})$$
                      - $Y_{ij}$ 是第 i 个样品标签中属于第 j 类的编码，是第 j 类就是 1，不是就是 0；$\hat{Y_{ij}}$ 是第 i 个样品的第 j 类的预测概率，由**Softmax 函数输出的 Z 向量**(牛逼)得出，K 是类别数量，n 是样本数
                      - 注意这里的样本数 n 表示，对于输入层输入的是很多张图片、甚至是不同类图片的情况（一个 batch），最后的损失值是将的所有图片的损失值进行求和
                      - 注意：多元交叉熵损失函数只适用于对一个类别进行预测，他假设每个样本或检测框只属于一个类别。原因是多元交叉熵函数之前通常会搭配 softmax 函数，这意味着一个类别的分数会影响到其他所有类别的分数，所以各个类别的判断之间并不互相独立，所以不能用来对一个目标做多类别预测。
           3. 梯度下降算法：
              1. 概念：
                 - 对于非线性函数 $y=f(x,w,b)$ ,其中 w、b 分别是权重和偏置，在此处共同影响函数走势，神经网络的目的就是通过学习获得一组最优的 w、b 值，使得损失函数取得最小值，而对于损失函数 $L(w,b)$来说，其有两个自变量 w，b，是一个空间中的二元函数，对于多元函数来说，**负梯度方向**是函数值减小最快的方向，为了让损失函数值以最快速度下降，应当让 w、b 沿着各自负梯度方向减小，所以每次得出损失函数之后应当按照负梯度方向更新 w、b,其中二元函数的梯度向量可以表示为：$∇L = [\frac{∂L}{∂w}, \frac{∂L}{∂b}]$ ，$L()$ 关于 w、b 的的梯度分别是 $\frac{∂L}{∂w}$、$\frac{∂L}{∂b}$ ,以下均用 $g$ 表示。
              2. 公式：
                 - $$w = w - α * g$$
                 - $$b = b - α * g$$
                 - 这里的$\alpha$控制梯度下降的步长，是学习率
              3. 针对遇到的问题在原有梯度下降算法算法上做出的改进：**其实就是解决梯度下降算法中每一轮$w$、$b$减多少的问题**
                 1. 内存开销问题：
                    - 更新一次 w、b 值，需要计算出当前所有样本点的预测值，并交由损失函数计算，如果遇到样本点数量极多的情况，储存这些计算结果需要很大的内存开销，
                    - 解决方法：
                      - 算法：**随机梯度下降**:所以针对所有样本点，每次更新只随机且不重复地使用当中的一部分样本点，这样 w、b 依然可以沿着正确的方向收敛，同时加快计算速度，减轻内存负担
                 2. 损失函数震荡问题：
                    - 损失函数在梯度优化时，参数点可能在一个"山谷"的两侧来回震荡，即每次的梯度优化过于激进，不够平滑，导致损失函数迟迟无法掉入山谷，或者学习率控制的步长没有在后期需要细致优化时变得更小，始终保持不变，造成震荡，无法收敛
                      1. 从梯度角度解决：
                         - 算法：**动量随机梯度下降**：引入上一次的梯度作为“动量”，与这一次的梯度方向做矢量和成为新的梯度方向，这样可以使得每次的优化更加平滑
                         - 公式：
                           - $$v=\beta v-\alpha g$$
                           - $$w=w+v$$
                           - $$b=b+v$$
                           - 其中$v$是新引入的动量，初值是 0，$\beta$是动量因子，控制对历史动量的保留程度，是超参数
                           - 此处的动量和一阶矩还是有区别的，动量是是过去梯度的累积，用于帮助优化算法在梯度方向上保持稳定的移动；一阶矩是过去梯度的指数移动平均值，用于平滑优化过程
                      2. 从学习率角度解决：
                         - 网络优化初期，梯度调节需要快速进行，可以大大提高效率，但是后期要想成功收敛，梯度调节的步长必须根据梯度大小等因素自行调节，梯度小时进行细致优化
                         1. 算法 1:**Adagrad 算法**
                            - 公式：
                              - $$r=r+g^2$$
                              - $$w=w-\frac{\alpha}{\sqrt{r}+\delta}g$$
                              - $$b=b-\frac{\alpha}{\sqrt{r}+\delta}g$$
                              - 其中$r$是引入的梯度大小随时间的积累量，即**二阶矩**，在此处使用了指数移动平均(EMA)算法计算二阶矩，即近期数据的权重永远大于早期数据的权重，而且随着新数据到来随时更新，最后也不计算平均值，初值为 0，$\delta$是为了防止分母为零引入的极小量
                            - 优点：如果一个参数的梯度经常很大，那么$r$的值会变大，导致这个参数的学习率下降；反之，如果一个参数的梯度经常很小，那么$r$的值会变小，导致这个参数的学习率上升。这样就可以实现对每个参数的学习率进行自适应调整。
                            - 不足：就是由于$r$是一直累积梯度平方的，所以在训练后期，$r$的值可能会变得很大，导致学习率过小，进一步导致训练过早停止。
                         2. 算法 2:**RMSprop 算法**
                            - 公式：
                              - $$r=\rho r+(1-\rho)g^2$$
                              - $$w=w-\frac{\alpha}{\sqrt{r}+\delta}g$$
                              - $$b=b-\frac{\alpha}{\sqrt{r}+\delta}g$$
                              - $\rho$：衰减率，其为超参数，训练过程中不可人为改变，通常值为 0.9 或 0.99，确定$\rho$ 需要通过交叉验证
                              - $r$ ：同样是二阶矩，代表了梯度随时间积累的量
                            - 优点：其中相较于 Adagrad 算法优势体现在加入了可以手动调节的$\rho$，通过不断减小过去数据在总二阶矩中所占权重，可以解决后期二阶矩不断增大导致的学习率过小的问题
                            - 不足：$r$ 初值过小，
                      3. 同时从梯度角度和学习率角度：
                         - **Adam 算法**
                           - 公式：
                             - $$s=\rho _1s+(1-\rho _1)g$$
                             - $$\hat s=\frac{s}{1-{\rho _1}^t}$$
                             - $$r=\rho _2r+(1-\rho _2)g^2$$
                             - $$\hat r=\frac{r}{1-{\rho _2}^t}$$
                             - $$w=w-\frac{\alpha \hat s}{\sqrt{\hat r}+\delta}$$
                             - $$b=b-\frac{\alpha \hat s}{\sqrt{\hat r}+\delta}$$
                             - $s$ 是自适应动量，或者说是一阶矩，继承自动量随机梯度下降算法；$r$ 是引入的梯度随时间积累的量，即二阶矩继承自 Adagrad 算法；$\rho_1$、$\rho_2$ 是衰减率，继承自 RMSprop 算法；$\hat s$、$\hat r$ 分别是 $s$ 和$r$ 随迭代过程的修正值
                             - $\rho_1$、$\rho_2$ 衰减率一般设置为 0.9 或 0.99，这表明二阶矩中越新的数据所占权重越大，因为新数据权重始终为(1-$\rho$),但是所有的老数据的权重随数据更新在逐渐减小
                             - 之所以创建$\hat s$、$\hat r$,是因为$s$、$r$ 初值较小，接近于 0，不能使用，但是后续两值会回归正常，使用公式则可以将初期的$s$、$r$ 放大，之后随着数据的更新，迭代的进行，分母中的$1-{\rho}^t$ 将逐渐接近于 1，即，后期$\hat s$、$\hat r$ 将逐渐等于于$s$、$r$，而此时$s$、$r$的值也随着一阶、二阶矩的积累过程回归正常。
        2. 反向传播算法：(BP 算法)
           1. 概念：神经网络中加速计算参数梯度值的方法
           2. 一般的计算各个参数梯度值的方法：
              - **前向传播过程**$$x >>> (w_1,b_1)>>>y_1=w_1x+b_1>>>(w_2,b_2)>>>y_2=w_2y_1+b_2>>>L(y_2,y_{gt})$$
                - 其中，$(w_1,b_1)$、$(w_2,b_2)$ 分别是前后两次线性运算的参数，最后损失函数$L(y_2,y_{gt})$ 中 $y_{gt}$ 是真实值，$y$是计算值
              - **反向传播过程**$$\frac{∂L}{∂b_1}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂y_1}\frac{∂y_1}{∂b_1}=\frac{∂L}{∂y_2}w_2<<<\frac{∂L}{∂w_1}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂y_1}\frac{∂y_1}{∂w_1}=\frac{∂L}{∂y_2}w_2x<<<\frac{∂L}{∂b_2}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂b_2}=\frac{∂L}{∂y_2}<<<\frac{∂L}{∂w_2}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂w_2}=\frac{∂L}{∂y_2}y_1$$
                - 其中每一步需要的量都由前向传播过程已知或由上一步已知
           3. 计算机中模块化加速计算梯度值方法
              - **前向传播过程**$$(x,w_1)>>>u_1=w_1x>>>(u_1,b_1)>>>y_1=u_1+b_1>>>(w_2,y_1)>>>u_2=w_2y_1>>>(u_2,b_2)>>y_2=u_2+b_2>>>L(y_2,y_{gt})$$
                - 其中与一般计算不同的是这其中引入了单元运算概念，即将所有复杂运算拆解成一个个的简单、步骤高度重合、只是数值发生改变的运算，这样就可以将正向传播和反向传播过程用程序来实现
              - **反向传播过程**$$\frac{∂L}{∂w_1}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂u_2}\frac{∂u_2}{∂y_1}\frac{∂y_1}{∂u_1}\frac{∂u_1}{∂w_1}=\frac{∂L}{∂y_2}w_2x<<<\frac{∂L}{∂b_1}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂u_2}\frac{∂u_2}{∂y_1}\frac{∂y_1}{∂b_1}=\frac{∂L}{∂y_2}w_2<<<\frac{∂L}{∂w_2}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂u_2}\frac{∂u_2}{∂w_2}=\frac{∂L}{∂y_2}y_1<<<\frac{∂L}{∂b_2}=\frac{∂L}{∂y_2}\frac{∂y_2}{∂b_2}=\frac{∂L}{∂y_2}$$
                - 其中每一步需要的量都由前向传播过程已知或由上一步已知
              - 计算机模块化和计算方法深度学习框架相配合，在每个单元运算中均有定义的正向传播和反向传播函数，给每个神经元之间创造了联系通路，神经元拥有了生命。
        3. 神经网络训练的过程，其实就是**前向传播计算数值**>>>**反向传播算法获取梯度**>>>**梯度下降算法更新参数**
   - CNN应用领域：
     1. 目标分类：
        1. **LeNet**：1998 年由**Yann LeCun(杨立昆)** 等人提出，定义了CNN卷积层、池化层、全连接层的基本结构，是CNN的鼻祖
        2. **AlexNet**：2012 年由**Alex Krizhevsky**、**Ilya Sutskever**和 **Geoffrey Hinton** 提出，是当时深度最大的卷积神经网络，大规模使用修正线性单元Relu和 Dropout 技术防止过拟合，同时使用了数据增强、分组卷积等技术，并首次在 GPU 上实现神经网络的训练，t 在 2012 年的 ImageNet 挑战赛中取得了 15.3% 的 Top-5 错误率，远低于当时第二名的 26.2%，标志着深度神经网络对于人类的触手可及。
        3. **ZFNet**：2013年由**Matthew Zeiler**和**Rob Fergus**提出，是对AlexNet的一种改进，首次引入可视化卷积网络的技术，在当年的ImageNet竞赛中夺冠。
        4. **VGGNet**：2014年由牛津大学的视觉几何组（Visual Geometry Group，VGG）提出的一种深度卷积神经网络结构，堆叠这些结构简单的基本模块来构建深度网络，证明了增加网络的深度可以显著提高模型的性能。
        5. **GoogleNet**：2014年由Google的研究人员提出，主要特点是引入Inception模块和辅助分类器，其中Inception模块包含了多个并行的卷积层和池化层，这些层的输出会在通道维度上进行拼接，形成更丰富的特征表示；辅助分类器位于网络的中间层，用于进行中间层的监督，以防止模型过拟合，在2014年ImageNet竞赛中夺冠。
        6. **ResNet**：2015年由微软研究院的研究员**何恺明**等人提出，主要特点是引入了残差结构，每个残差块包含了两个或三个卷积层，这些卷积层的输出会和输入进行相加，形成一个“短路连接”，使得网络更容易学习恒等映射，从而避免了深度网络中的性能退化问题；除此之外还使用了批量归一化和全局平均池化技术，在2015年ImageNet竞赛中夺冠。
        7. **DenseNet**：2016年由Gao Huang等人提出，主要特点是网络层之间的密集连接。在传统的卷积神经网络中，每一层的输出只会被下一层使用。但在DenseNet中，每一层的输出都会被所有后续的层使用，这改善了反向传播过程，使得网络可以更深
     2. 目标检测：
        1. RCNN 系列：
           1. **RCNN**：2014年由Ross Girshick等人提出，主要思想是首先使用区域提议方法生成一些候选区域，然后对每个候选区域使用卷积神经网络（CNN）提取特征，最后使用SVM进行分类，使用线性回归进行边界框回归，计算较为复杂
           2. **Fast R-CNN**：2015年由Ross Girshick提出，特点是引入了RoI Pooling层(特征提取技术)，先使用Selective Search传统方法生成候选区域，然后使用RoI对每个候选区域进行特征提取，大大提高了计算效率；Fast R-CNN还将分类和边界框回归合并到一个网络中进行，简化了训练过程。
           3. **Faster R-CNN**：2015年提出，主要特点是引入了区域提议网络RPN，代替Selective Search传统方法直接生成候选区域，然后使用RoI提取特征，将候选区域的生成和特征提取融合在一个网络中，提高了计算效率
        2. YOLO 系列：
           1. **YOLOV1**：2015年提出
           2. **YOLOV2**: 2016年提出
           3. **YOLOV3**: 2018年提出
           4. **YOLOV4**: 2020年提出
           5. **YOLOV5**: 2020年提出
           6. **YOLOX**: 2021年由 Megvii (Face++) 的研究人员提出，是 YOLOv4 和 YOLOv5 的改进版本，具有更高的准确性和速度，采用了全新的Anchor-Free 设计，引入动态标签分配。
              - 大致结构：
                  1. **输入层**：处理输入的数据，使用Mosaic、Mixup数据增强处理输入的数据
                  2. **Backbone**：提取图像特征，使用了残差网络ResNet中的残差单元和空间金字塔网络SPPNet中的特征金字塔池化SPP结构
                  3. **Neck**：特征融合和特征选择，使用了特征金字塔网络FPN中的结构
                  4. **Head**： 处理预测框信息、损失函数计算、输出，首创了解耦头结构以及优化了标签分配方法
           7. **YOLOV8**:
     3. 目标分割：
        1. 语义分割：不区分属于相同类别的不同实例
           1. FCN全卷积网络
           2. UNet
        2. 实例分割：区分属于相同类别的不同实例
           1. Mask RCNN
3. **GAN**生成对抗网络：
   1. 初步理解：生成对抗网络核心思想是**二人零和博弈**，即**生成器**和**判别器**通过不断对抗来提高自身性能，最终达到纳什均衡
      1. 生成器：
         1. 所做的事：根据所给的随机数生成图片
         2. 目标：使得生成的图片越来越真，直到骗过判别器，让其无法分辨真假
         3. 学习源：判别器
      2. 判别器：
         1. 所做的事：对来自生成器的图片进行判断，辨别其是否是真实图片
         2. 目标：增强对真假图片的判别能力，直到能够准确无误的将所有来自生成器的图片都判别为假
         3. 学习源：训练时所给的数据集和生成器生成的图像
   2. 几种生成对抗网络的结构
4. **GNN**图神经网络
5. **DDPM**扩散模型
6. **Transformer** 变压器模型：
   1. 介绍： Transformer 模型 2017 年由谷歌研究员在Ashish Vaswani等在《Attension is all you need》中提出，问世之后成一众大语言模型的结构基础，被证明尤其在自然语言处理领域效果极其显著
   2. 主要结构：**输入**->**多个编码器**->**多个解码器**->**输出**
      1. 输入
         1. Word Embedding(词嵌入)：
            1. 所有模型本身只能处理数据，不能直接处理文本、语言，需要将一个小句拆分成一个个 **token**，即文本处理的基本单位，可以是一个个字，也可以是字词组合，并使用某种方法将每个 token 转换为**编码向量**，这样的话一个小句就变成了一个**二维数据**形式，即token 数维度和编码维度，与图像处理任务中输入的图像数据不同的是这里没有通道维度，所以输入的数据形式是[批次数，token 数，编码长度]。将 token 转换为编码向量的方法具体可以使用Tomas Mikolov 等人在 2013 年提出的**Word2Vec**模型：使用一个神经网络将词语映射到向量空间中，并且相近语义的词语在向量空间中的距离较近，该模型主要有两种结构：
               1. CBOW(Continuous Bag of Words): 通过上下文预测目标词，使用小数据集，训练速度快
               2. Skip-gram: 通过目标词预测上下文词，适用于大数据集，，可以捕获更多的语义信息
            2. 一个小句中的每个 token 都转换为向量之后，拼接成一个矩阵，形状为[token数，编码长度]，
         2. Positional Encoding(位置编码):
            1. 词嵌入步骤得到的矩阵，只包含了当前输入模型的文本的内容，不含每个token 在原句中的位置信息，但是在日常翻译中，每个字在句中的位置对与整句话语义的理解也极其重要，所以我们需要在词嵌入矩阵的基础上加入包含每个 token 的位置信息，这里可以使用。。和公式计算实现，Transformer 使用的是公式计算。
            2. 方法
               1. Embedding方式；
               2. 公式计算：
                  -  $$\begin{cases}PE_{(pos,2i)} = \sin(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\\ PE_{(pos,2i+1)} = \cos(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\end{cases}$$
                     1. 其中$pos$表示此token在原句中的位置(0、1、2……)，$i$ 表示此 token向量中的维度索引，$d_{model}$ 表示位置编码的维度总数，即有多长
                  - 优势：
                    1. 由于底层是数学公式，且正弦、余弦函数的定义域是整个实数域，所以其具有**外推性**，即位置编码不仅适用于训练集中出现的序列长度，还可以适用于更长的序列。这种外推性使得模型能够在推理阶段处理比训练集更长的句子
                    2. 使用这样的公式，可以为每个位置的 token 生成一个在其存在的小句中至于其所处位置有关的独一无二的位置编码，将这个编码加入到原先的向量中，就让向量从此具有了此 token 的语义、位置信息，模型可以学习到每个 token 在句中的绝对位置对语义的影响关系
                    3. 模型可以学习到不同 token 之间相对的位置关系对整个语句语义的影响：由于 cos、sin 可拆分的性质：$$\begin{cases}\sin(a + b) = \sin(a)\cos(b) + \cos(a)\sin(b)\\ \cos(a + b) = \cos(a)\cos(b) - \sin(a)\sin(b)\end{cases}$$ 任意 $pos+k$ 处的位置编码，可以用$pos$位置的编码的线性组合表示,即：$$\begin{cases}PE_{(pos+k,2i)}=\sin(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\cos(\frac{k}{10000^{\frac{2i}{d_{model}}}})+\cos(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\sin(\frac{k}{10000^{\frac{2i}{d_{model}}}}) \\ PE_{(pos+k,2i+1)}=\cos(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\cos(\frac{k}{10000^{\frac{2i}{d_{model}}}})+\sin(\frac{pos}{10000^{\frac{2i}{d_{model}}}})\sin(\frac{k}{10000^{\frac{2i}{d_{model}}}})\end{cases}$$，
                    4. 正弦、余弦函数的变化频率随着维度的增加而发生改变，维度越低，数值变化频率越快，周期越小，适合捕捉短距离位置依赖关系；维度越高则适合捕捉长距离的位置依赖关系
      2. 编码器：
         1. 整体结构：**Multi-Head Attention**->**Add & Norm**->**Feed Forward**->**Add & Norm**
         2. 具体结构分析：
            1. **Multi-Head Attention**(多头注意力模块)：
               1. 多头注意力的核心是 Self Attension(自注意力机制)，二者相当于整个卷积层和单个卷积核之间的关系，显然，卷积核是整个卷积层工作的核心，所以需要先弄清楚什么是自注意力
               2. **Self Attension**(自注意力机制)：以矩阵形式讲解
                  1. 根据**输入矩阵**和自身的**权重矩阵**计算**查询矩阵 Q**、**键矩阵 K**、**价值矩阵 V**：
                     -  $$\begin{cases} Q=W^{input}W^Q \\ K=W^{input}W^K \\ V=W^{input}W^V \end{cases}$$
                        1. 这里的输入矩阵 **$W^{input}$** 为一个小句中所有 token 向量的整合，形状：[token 数，编码长度]，由输入或上一级编码器输出得到
                        2. 每个自注意力模块都有三个权重矩阵：**$W^Q$**、**$W^K$**、**$W^V$**，属于该模块自身的可更新参数，为满足点积的条件，其形状为[每个token的编码长度，自定义(但是一般比 token 向量维度小)]，产生的三个矩阵 Q、K、V 形状相同
                        3. 将矩阵乘法拆开来看，两矩阵点积的过程其实就是输入的每个 token 向量分别于三个权重矩阵相乘的过程，只不过为了加速运算，都是拼接成矩阵来进行
                  2. **查询矩阵 Q** 与**键矩阵 K** 点积，得到**注意力分数矩阵 $QK^T$**
                     -  $$QK^T=\frac{Q·K^T}{\sqrt{d_k}}$$
                        1. 由于 Q、K、V 形状相同，且不是方阵，故不能直接点积，需要将 K 转置，
                        2. 拆开来看，查询矩阵 Q 的每一行,即每个 token 对应的向量,分别与转置前 K 矩阵中的每一行,同样是每个 token 对应的向量分别相乘，得到了每个token 相对于包括自己的所有 token 的注意力分数，每个 token 产生数量等于 toke 总数的注意力分数，故所得结果注意力矩阵$QK^T$的形状是一个方阵，行和列都等于 token 数，其中每一行代表一个 token，每一列代表这个 token 在其他 每一个token上的注意力大小，这也是注意力机制的核心
                        3. 同时为了防止点积的结果过大，还将点积的结果矩阵除以$\sqrt{d_k}$,即 K 矩阵中每个 k 向量的维度大小的开方
                  3. 对点积结果 **Softmax** 归一化：
                     - $$Softmax(QK^T)$$
                     1. 将注意力分数矩阵的每一行分别归一化，将各个注意力分数映射到 0-1 之间，相加为 1
                  4. 将归一化结果与价值矩阵点积得到新的价值矩阵
                     - $$V=Softmax(QK^T)V$$
                        1. 归一化结果矩阵中引入了每个token 的对于每个其他 token 的**注意力**，将这个过程拆开来看就是让每个 token 向量的每个维度都变成其他所有 token 在这个维度的值与其被关注的注意力的乘积之和
               3. **Multi-Head Attention**：多头注意力其实就是采用了多个自注意力模块，每个模块被称为一个“头”，拥有自己的参数，不共享，针对同一个输入矩阵，每个模块都会产生一个输出矩阵，并将所有单个输出矩阵按列拼接得到一个大矩阵，然后使用**全连接层**将这个大矩阵映射成一个和单个注意力模块输出矩阵形状相同的矩阵，这是为了后面残差操作的方便，此时这个新的输出矩阵的每一行都是表示一个 token 的**编码向量**。
            2. **Add & Norm**(残差连接+特殊归一化)：
               1. 残差结构：这里为了让编码器网络整体可以做的更深，引入了残差的思想，编码器结构中出现了两次：
                  1. 多头注意力模块之后，Feed Forward之前：将每个编码器的输入矩阵和经过多头注意力的输入编码矩阵直接逐元素相加，让网络学习到输入的残差特性
                  2. Feed Forward 之后，编码器输出之前： 将输入到Feed Forward的矩阵和Feed Forward的输出矩阵逐元素相加，同样是为了让网络可以做到更深。
               2. **LayerNorm**：即Layer Normalization，与 Batch Normalization 不同，后者利用的是批次内同一个通道中的特征值，而这里考虑到数据不包含通道维度，所以使用了LayerNorm，即将单个输入矩阵内的数据在**token 数**、***编码长度** 上进行归一化，归一化内部算法实现与Batch Normalization相同。
            3. **Feed Forward**(前向全连接层)：这里使用的就是普通的全连接层，将Add & Norm操作之后的输出矩阵转化为一个新的输出矩阵，形状不变，这个输出矩阵也作为这个编码器的最终输出进入到后面的编码器中，或作为最后一层编码器网络的输出传递到解码器中。
      3. 解码器：
         1. 整体结构：**输入**—>**Masked Multi-Head Attention**->**Add & Norm**->**Multi-Head Attention**->**Add & Norm**
         2. 具体结构分析：
            1. 输入：
               1. 解码器网络和编码器网路的一个不同点是：除了第一个之外的每个解码器都同时接收**上一级解码器输出的数据**和**最后一级编码器输出的数据**，而第一个解码器的输入则是由 **SOS** 、**真值**、**EOS** 的编码向量组成的矩阵， 其中SOS、EOS 分别为**开始符**和**结束符**，表示一句话的开始和结束，Transformer 采用了 **TeacherForcing** 的训练方式：在训练时将正确答案，即真值也作为训练数据喂入网络中，且网络同时输出一个小句中的所有token 的编码向量；推理时，模型一次前向传播(时时间步)则只产生一个 token 的编码向量，即一个词一个词(或字)去预测，模型每次前向传播进入解码器第一层的是**当前所有已预测的token的编码向量**，预测第一个token 时输入的则是 SOS，表示预测的开始。
            2. **Masked Multi-Head Attention**(掩码多头注意力模块)：
               1. 在训练翻译的时候，由于TeacherForcing训练方式将翻译目标小句中的所有 token真值也输入解码器，但我们不能让解码器在计算当前 token 对其他 token 的关注度时出现**对还未翻译到的词加以关注的现象**，即不能让解码器看到他还没翻译到的词语的答案，只能让他根据**需要被翻译的整个句子**和**已经翻译出来的所有词语**来继续进行下一个词的翻译，所以说，需要将输入矩阵进行一下掩码操作，这也就是掩码多头注意力和普通多头注意力的主要区别
               2. 过程：
                  1. 首先将输入的编码矩阵输入到结构中，接着进行和**普通多头注意力完全相同**的步骤进行计算，得到softmax 归一化之后的注意力方阵。
                  2. 紧接着，我们引入**掩码矩阵**，即一个下三角矩阵，主对角线及以下区域均为 1，其他区域均为 0，使其与得到的 softmax 归一化之后的注意力方阵进行位积，即逐元素相乘，即可屏蔽掉每个 token 对他之后的 token 的注意力，使得每个 token 只会对其之前的 token 投以注意力，这避免了解码器在解码当前 token 的编码时看到来自未来的他还没有解码的 token 的信息
                  3. 之后，同样是与 价值矩阵V点积，得到新的价值矩阵，注意这里如果拆开看的话，新价值矩阵中的每个 token 编码向量在产生时仅包含了本身及其之前token 向量的价值，不包含其之后token 的价值
                  4. 之后和多头注意力一样，多个注意力头的输出矩阵拼接、映射成一个与输入形状相同的编码矩阵
            3. **Multi-Head Attention**：
               -  这里的多头注意力模块和编码器的多头注意力模块几乎完全一样，唯一的不同之处在于其价值矩阵 V 由上一级的解码器输出的编码向量计算而来，即： $$V=W^{上级输出} W^{V}$$,但是查询矩阵 Q 和键矩阵 K 由最后一层编码器输出的编码矩阵计算而来，即：$$ Q=W^{最后一层编码器} W^{Q} $$  $$ K=W^{最后一层编码器} W^{K} $$ 这也同时映衬了这里不需要加入掩码操作，因为这里的注意力方阵产生过程所依赖的 Q、K 矩阵都是由编码器的输出得来的，是模型对所给小句整体的预测，而不含有目标真值小句中的任何元素，也就没有什么来自未来的词一说，这与第一个掩码多头注意力模块不同，其 Q、K 均来自目标真值，相反，这里恰恰需要对小句中的所有 token 进行注意力分配，因为理解语义的过程需要依赖整个句子。
            4. **Add & Norm**：与编码器中的相应结构完全相同，其结果就是此解码器的输出
      4. 输出：
         -  对于最后一层解码器输出的编码矩阵，我们需要将其映射到**一个长度等于目标语言库中 token 总数，宽度不变的矩阵logits**，这里我们使用了一个简单的全连接层实现，并在之后对其进行逐行的 softmax 操作，之后其实就是一个多分类问题，**标签矩阵**的形状是[目标 token 数，目标词典中 token总量]，使用交叉熵损失函数计算。

---
## 实战
1. **配python环境**：
   1. 双系统安装：
      1. 
   2. 显卡驱动：
      1. windows：
      2. Ubuntu：
   3. CUDA 安装：
      1. 如何检查自己安装的CUDA 版本？
         1. `nvidia-smi`:可以显示自己显卡的驱动和 CUDA 信息
   4. CONDA 环境：
      1. conda 的功能：
         1. conda主要被用作 **python 环境管理器**，主要作用是针对不同的项目，创建、管理不同的 python 环境，以避免多个项目使用同一环境时会出现的依赖冲突问题
      2. 安装 conda：
         1. windows：
            1. 下载地址：[Anaconda](https://www.anaconda.com/products/distribution)
            2. 安装：双击下载的安装包，一路下一步即可
         2. Ubuntu：
            1. `wget https://repo.anaconda.com/anaconda/Anaconda3-latest-Linux-x86_64.sh`，终端输入，获取最新的Anaconda安装包
            2. `bash XXX.sh`，XXX 替换为下载得到的安装包名，安装Anaconda
            3. `source ~/.bashrc`,更新环境变量，使其 conda 环境生效
            4. `conda --version`,验证安装是否成功
      3. conda 的使用技巧：
         1. 对python环境整体的操作：
            1. `conda env list`:显示当前所有的 python 环境
            2. `conda create --name env_name python=3.8`:创建一个名为 env_name 的 python3.8 环墶
            3. `conda env remove --name env_name`:删除名为 env_name 的 python 环境
            4. `conda create --name new_env --clone old_env`：复制一个 python 环境
            5. `conda activate env_name`:激活名为 env_name 的 python 环境
            6. `conda deactivate`:退出当前 python 环境 
   5. PIP 包管理器 ：
      1. pip 的功能：
         1. pip 是 **python 包管理器**，主要作用是下载、安装、卸载 python 包 ，我个人一般喜欢搭配 conda 使用，即使用 conda 管理 python 环境，使用 pip 管理 python 包。使用 conda 创建好 python 环境后，一般会自动安装 pip 包管理器
      2. pip 的使用：
         1. `pip install package_name`:安装名为 package_name 的 python 包
         2. `pip install package_name -i https://pypi.tuna.tsinghua.edu.cn/simple`:使用清华镜像源安装名为 package_name 的 python 包
         3. `pip uninstall package_name`:卸载名为 package_name 的 python 包
         4. `pip list`:显示当前 python 环境中所有的 python 包
         5. `pip freeze > requirements.txt`:将当前 python 环境中所有的 python 包导出到 requirements.txt 文件中
         6. `pip install -r requirements.txt`:根据 requirements.txt 文件中的包名，安装所有的 python 包
2. **pytorch框架**
    1.  命令行参数解析传入阶段：
      1.  总述：这个部分虽然不是 pytorch 中的一个特殊模块，但是对于神经网络的搭建和使用至关重要
      2.  库导入：`import argparse`
      3.  使用方法：
         1. 
    2.  数据加载阶段：
        1.  总述：对于 pytorch 模型训练，需要先将训练的数据(如图片等)进行打包，创建一个数据集对象，使其包含这个数据集合，之后再利用这个数据集对象创建一个数据加载器对象，负责一个批次一个批次地向模型推送数据和对应标签
        2.  **Dataset类**数据集：
         3. 导入：`from torch.utils.data import Dataset`
         4. 使用方法：
            1. 直接使用：
               - `dataset=Dataset(path/to/your/datasets)`直接创建一个数据集对象，将数据集路径参数传递给Dataset
            2. 定义一个自己的数据集类：
               1. 
        3.  **Dataloader类**数据加载器：
         4. 导入：`from torch.utils.data import Dataloader`
         5. 创建一个数据加载器对象：`dataloader=DataLoader(dataset,batch_size,shuffle, num_workers) `
            1. **dataset**:之前定义好的数据集对象
            2. **batch_size**：批次数，每次迭代进入网络内部的图片数
            3. **shuffle**：是否数据洗牌，即每个 epoch 开始时是否将数据集中的数据打乱，Ture/Falth
            4. **num_workers**： 数据加载时使用的进程数
    3.  模型结构定义阶段：
      1.  总述：pytorch 的核心即预定义好了一系列网络核心构件，可以让使用者像搭积木一样拼接网络，所有包含在模型通路中的组件，都需要是 `Module`子类，这样才可以被参数更新
      2.  几个模块：
         1. **nn模块**: 神经网络模型模块
            1. 导入：`import torch.nn`
            2. 使用方法：
               1. `class name(nn.Module):`:在父类基础上继承自己的模型子类
               2. `super(name,self).__init__()`：初始化父类
               3. 模块中预定义的**卷积层**：
                  1. `nn.Conv2d(in_channels,out_channels,kernel_size,stride)`: 二维卷积层，最常用于处理图像数据。
                     1. in_channels:输入通道数
                     2. out_channels:输出通道数
                     3. kernel_size：卷积核大小
                     4. stride：卷积步长
                  2. `nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, output_padding)`: 二维转置卷积层，用于图像数据的上采样，常见于生成对抗网络（GANs）
                     1. in_channels:
                     2. out_channels:
                     3. kernel_size:
                     4. stride:
                     5. padding:
                     6. output_padding:
                  3. `nn.DepthwiseConv2d`: 深度可分离二维卷积层，其中每个输入通道被单独卷积。
                     1. 
                  4. `nn.GroupConv2d`: 分组卷积层，它将输入和输出通道分成多组，以减少参数数量和计算量。
               4. 模块中预定义的**批量归一化层**：
                  1. `nn.BatchNorm2d(in_channels)`:批量归一化，对当前批次中的特征图中特征值进行归一化
                     1. in_channels：输入通道数
               5. 模块中定义的**激活函数层**：
                  1. `nn.Relu()`: Relu 激活函数，直接使用，不包含可更新参数
               6. 模块中定义的**池化层**：
                  1. `nn.MaxPool2d(kernel_size=2, stride=2)`:最大池化层，用于提取局部区域中的最大值
                     1. kernel_size：卷积核尺寸
                     2. stride：卷积核移动步长
                  2. `nn.AvgPool2d(kernel_size=2, stride=2)`：平均池化层，用于计算局部区域的平均值
                  3. `nn.AdaptiveAvgPool2d(1)`，全局平均池化层，在每个通道上取整个特征图的平均值，通常用于分类任务的最后一个池化层，以减少特征图的尺寸到1x1
               7. 模块中定义的**全连接层**：
         2. **functional类**：函数模块
         3. 导入：`import torch.nn.functional`
         4. 模块中预定义的函数：
            1. 上/下采样：
               1. `functional.interpolate(image, scale_factor, mode, align_corners)`
                  1. image:输入图像
                  2. scale_factor：缩放因子（0～正无穷）
                  3. mode：缩放模式，有：
                     1. ‘bilinear’：双线性插值
                     2. 
                  4. align_corners：是否对输入输出的角落像素进行对齐，设置为False可避免潜在锐化
    4.  训练、推理阶段：
         1. 定义损失函数和梯度优化器：
         2. 常用损失函数：
            1. `nn.CrossEntropyLoss()`：交叉熵损失函数，用于多分类
               1. model_output：模型的全连接层输出，不需要经过 softmax
               2. target：标签
            2. `nn.BCELoss()`：二元交叉熵损失函数，用于二分类
               1. model_output：模型的全连接层输出
               2. target：标签
            3. `nn.BCEWithLogitsLoss()`：带有 logits 的二元交叉熵损失函数
               1. model_output：模型的全连接层输出
               2. target：标签
            4. `nn.MSELoss()`：均方误差损失函数
               1. model_output：模型的全连接层输出
               2. target：标签
            5. `nn.L1Loss()`：最小绝对误差损失函数
               1. model_output：模型的全连接层输出
               2. target：标签 
         3. 常用梯度优化器：
            1. 导入：`import nn.optim as optim`
            2. `optim.SGD(params, lr)`:随机梯度下降,最基本的优化器，适用于大多数情况
            3. `optim.RMSprop(params, lr)`:适用于处理非平稳目标和非线性优化问题。
            4. `optim.Adam(params, lr)`:自适应矩估计,结合了动量和 RMSprop 的优点，适用于大多数非凸优化问题，是目前最流行的优化方法之一。
            5. `optim.AdamW(params, lr)`:对 Adam 的改进版本，添加了权重衰减，通常用于正则化和防止过拟合。
            6. `optim.Adagrad(params, lr)`:适用于处理稀疏数据.
            7. `optim.Adadelta(params, lr)`:是 Adagrad 的扩展，旨在减少其学习率的单调递减。
         4. 损失函数和梯度优化器的使用：
            1. 先创建损失函数对象criterion和梯度优化器对象optimizer
            2. 更新某一模块之前，首先梯度归零：`optimizer_d.zero_grad()`
            3. `criterion(model_output,target)`:使用损失函数得到损失值 loss
            4.  `loss.backward()` ：对损失使用反向传播算法，获取梯度
            5.  `optimizer_d.step()`：使用梯度下降算法更新参数
         5.  特殊使用：
             1. 在生成对抗网络中，生成器和判别器一般是先后训练，由于总的数据流是从生成器流向判别器，更新判别器参数时会默认把生成器也进行更新，所以需要在判别器的输入层将来自生成器的特征图进行信息切断，使其与生成器的模型没有关联关系：`discriminator(fake_images.detach())`
    5.  模型性能评估阶段:
    6.  模型权重保存、加载 
3. **计算机视觉**领域：
   1. 基于CNN的传统领域：CNN 的强项一直是图像处理，其问世之后很快得到了几乎所有图像或矩阵任务的使用
      1. 目标分类：
        1. **LeNet**：1998 年由**Yann LeCun(杨立昆)** 等人提出，定义了CNN卷积层、池化层、全连接层的基本结构，是CNN的鼻祖
        2. **AlexNet**：2012 年由**Alex Krizhevsky**、**Ilya Sutskever**和 **Geoffrey Hinton** 提出，是当时深度最大的卷积神经网络，大规模使用修正线性单元Relu和 Dropout 技术防止过拟合，同时使用了数据增强、分组卷积等技术，并首次在 GPU 上实现神经网络的训练，t 在 2012 年的 ImageNet 挑战赛中取得了 15.3% 的 Top-5 错误率，远低于当时第二名的 26.2%，标志着深度神经网络对于人类的触手可及。
        3. **ZFNet**：2013年由**Matthew Zeiler**和**Rob Fergus**提出，是对AlexNet的一种改进，首次引入可视化卷积网络的技术，在当年的ImageNet竞赛中夺冠。
        4. **VGGNet**：2014年由牛津大学的视觉几何组（Visual Geometry Group，VGG）提出的一种深度卷积神经网络结构，堆叠这些结构简单的基本模块来构建深度网络，证明了增加网络的深度可以显著提高模型的性能。
        5. **GoogleNet**：2014年由Google的研究人员提出，主要特点是引入Inception模块和辅助分类器，其中Inception模块包含了多个并行的卷积层和池化层，这些层的输出会在通道维度上进行拼接，形成更丰富的特征表示；辅助分类器位于网络的中间层，用于进行中间层的监督，以防止模型过拟合，在2014年ImageNet竞赛中夺冠。
        6. **ResNet**：2015年由微软研究院的研究员**何恺明**等人提出，主要特点是引入了残差结构，每个残差块包含了两个或三个卷积层，这些卷积层的输出会和输入进行相加，形成一个“短路连接”，使得网络更容易学习恒等映射，从而避免了深度网络中的性能退化问题；除此之外还使用了批量归一化和全局平均池化技术，在2015年ImageNet竞赛中夺冠。
        7. **DenseNet**：2016年由Gao Huang等人提出，主要特点是网络层之间的密集连接。在传统的卷积神经网络中，每一层的输出只会被下一层使用。但在DenseNet中，每一层的输出都会被所有后续的层使用，这改善了反向传播过程，使得网络可以更深
      2. 目标检测：
         1. RCNN 系列：
           1. **RCNN**：2014年由Ross Girshick等人提出，主要思想是首先使用区域提议方法生成一些候选区域，然后对每个候选区域使用卷积神经网络（CNN）提取特征，最后使用SVM进行分类，使用线性回归进行边界框回归，计算较为复杂
           2. **Fast R-CNN**：2015年由Ross Girshick提出，特点是引入了RoI Pooling层(特征提取技术)，先使用Selective Search传统方法生成候选区域，然后使用RoI对每个候选区域进行特征提取，大大提高了计算效率；Fast R-CNN还将分类和边界框回归合并到一个网络中进行，简化了训练过程。
           3. **Faster R-CNN**：2015年提出，主要特点是引入了区域提议网络RPN，代替Selective Search传统方法直接生成候选区域，然后使用RoI提取特征，将候选区域的生成和特征提取融合在一个网络中，提高了计算效率
         2. YOLO 系列：
            1. **YOLOV1**：2015年提出
            2. **YOLOV2**: 2016年提出
            3. **YOLOV3**: 2018年提出
            4. **YOLOV4**: 2020年提出
            5. **YOLOV5**: 2020年提出
            6. **YOLOX**: 2021年由 **旷视科技**(Megvii)的研究人员提出，源自 YOLOV3，具有对小目标更高的准确性和速度
               1. 训练过程的整体结构（有CSPDarknet、Darknet53两个版本，两者只在 backbone 部分有区别，其他部分基本一致）![yolox](picture/2.png)
                     1. **输入端**
                        1. 数据增强：
                           1. **Mosaic 数据增强**
                              - 大致过程：四张图片通过随机缩放、随机裁剪、随机排布的方式进行拼接，合成一张图片,这几张图片之间互相填充，填满整个输入图像的每个区域
                              - 优点：增加样本的多样性、提高模型对小而密集目标的识别能力、让模型在一个 batch 中处理更多张图片，提高 GPU 利用率
                           2. **Mixup 数据增强**
                              - 大致过程：将两张图片上下左右填充之后缩放到输入图片标准大小，然后设置一个叠加系数将两张图片上下叠加，相互融合，使得两张图片中的元素包含检测框也会相互重合
                              - 优势：增加样本多样性、引入随机性防止过拟合、实现简单
                           3. 需要注意：使用 Mosaic 和 Mixup 两种数据增强方式会让 ImageNet 预训练模型变得失去意义，因为所有数据集都得从头开始训练
                        2. 切片下采样：
                           1. 将每张图片复制为 4 份，分别经过四次不同的切片操作
                              - **slice**：表示切片过程，主要有四个参数
                                 1. **starts** ：表示切片起点，如果是[1,1],则表示从第二行第二列的元素开始切片
                                 2. **ends** ：表示切片的元素索引，如果是[9223372036854775807, 9223372036854775807]，这两个数是 python 中 64 位整数的最大值，表示切片到维度末尾
                                 3. **axes** ：表是切片的维度，对于四维张量而言，如果 axes=[2,3],则表示在每张图片的高度、宽度上切片
                                 4. **steps** ：切片步长，如果是[2,2],则表示两个维度上的都是每两个取一个
                           2. 切片之后对结果进行维度上的拼接，即进行 concat 操作
                     2. **Backbone**
                        1. 作用：**提取图像特征**
                        2. 构造: ![Backbone](picture/3.jpeg)
                           1. 基于**CSPDarkNet**的 Backbone:
                              1. 结构：
                                 1. **CSP 结构**：跨阶段部分连接层，思想来自于**CSPNet**，CSPDarkNet 的骨架，是一种特殊的层结构，将来自网络某一阶段的特征图分为两部分。一部分直接传递到后续阶段，而另一部分经过额外的处理（如卷积层）后再与直接传递的部分合并，这种方法减少了冗余计算，因为并非所有特征都经过每个卷积层的处理。它更注重于**提高网络的训练效率和降低计算成本**，同时保持特征的多样性，
                                 2. **特征重塑结构**：CSPLayer 内的基本结构，将卷积核、sigmoid 激活函数、乘法操作结合在一起，即卷积核输出的特征图先通过一次 sigmoid 函数将特征值转换为权重系数，然后将其与特征图逐元素相乘，得到最后的新特征图，这可以改变特征的分布或重要性，帮助模型专注于提取更重要的特征
                                 3. **Bottleneck 结构**：CSPLayer 中的标准神经网络构构件，此处是实现了残差连接功能的 Bottleneck 结构
                                    - 相比于 CSPLayer 中的其他构件，BottleNeck 主要负责实现残差连接功能，与**Resn**相同
                                 4. **SPP 结构** :空间金字塔池化(正常来说 SPP 的输出是一个固定长度的向量，但是 yolox 中略有不同，还是保留了其二维矩阵形状，因为空间位置信息对于目标定位非常重要，除此之外，其还使用外围填充和设置互动窗口步长为 1 的方案使得输出特征图尺寸和输入特征图相等)，思想来自于**SPPNet**
                                    1. 作用：提取多尺度特征
                                    2. 作用过程：输入特征图上进行不同尺度的最大池化操作，然后将这些不同尺度的特征图和**输入的特征图**拼接在一起，从而得到一组丰富的、多尺度的特征，其中在拼接之前，需要将所有特征图的尺寸调整为相同大小，可以使用类似于上采样操作中的最近邻插值、双线性插值等方法，最后是**在通道维度上相加(concatenation)**，也就是沿着通道轴堆叠起来。
                           2. 基于**DarkNet53**的 Backbone：
                              1. **CBL**：是一个常见层组合，即*Convolution-BatchNorm-LeakyReLU*，是将卷积层、批量归一化层、LeakyReLU 激活层组合在一起使用，在 YOLOXDarknet53 中使用广泛
                              2. **Resn**:残差网络**ResNet**中引入的一种残差连接，由残差块组成，Resn 就表示这个残差连接中包含 n 个残差块，相互串联连接，其中每个残差块通常结构如下：
                                 - **卷积层**(降低维度,残差单元的第一层，通常使用 1x1 的卷积核，步长为 1)
                                 - **激活层**(引入非线性,ReLU 激活函数)
                                 - **卷积层**(提取特征,接下来是一个 3x3 的卷积层，步长为 1)
                                 - **激活层**(再次使用 ReLU 激活函数)
                                 - **卷积层**(恢复维度,最后是一个 1x1 的卷积层，步长为 1)
                                 - **跳跃连接**(直接将最初的输入信号传递到最后一个卷积层的输出，并**逐元素相加**，如果输入的特征图大小和经过最后一个卷积层出来的特征图的尺寸或深度不一致，则会使用步长为一定值的 1\*1 卷积核将输入的特征图的尺寸和深度调整至于输出特征图一直，然后进行逐元素相加)
                                 - **激活层**(相加结果再通过 ReLU 激活函数，得到残差单元的最终输出)
                              3. **SPP** ：同 CSPDarkNet
                     3. **Neck**![Neck](picture/4.jpg)
                      1. 作用：特征融合和特征选择
                         1. 基于**FPN\*\***结构的 Neck 结构：
                            1. 结构思想：使用的是**特征金字塔网络（FPN）**中的结构，FPN 主要思想是构建一个多尺度融合金字塔，同时处理不同尺度目标，主要组成部分：**自底向上的常规卷积网络结构**、**自顶向下的上采样(只改变大小)和 1\*1 卷积核操作(只改变维度)**
                               1. **上采样**是一种增大特征图尺寸的操作，常见的上采样方法有最近邻插值、双线性插值等。在 FPN 中，上采样操作通常用于将高层（尺寸较小，**语义信息丰富**）的特征图尺寸放大，以便与低层（尺寸较大，**位置信息丰富**）的特征图进行融合。
                               2. 1\*1 卷积核操作则通过卷积核数量改变特征图的维度
                               3. **下采样**：是一种减少数据量的操作，通常指减少图像尺寸的过程，在 CNN 中，卷积层、池化层中均有下采样操作
                               4. 对于每一层，由前向传播过程得到的每张特征图会与上采样操作得到的特征图进行**维度上的相加**，得到新的特征图继续向下进行上采样操作，这样的构造会使得新的特征图即具有高层的语义信息还具有底层的位置信息，具有更好表达能力
                               5. **concat**：上采样中常用的融合结构，将两种特征图进行**维度**上的拼接
                            2. 将来自 Backbone 的三个层级的特征图进行融合之后再输出给 Prediction 结构
                         2. 基于**PAN**结构的 Neck 结构：
                            1. 在 FPN 的基础上增加了从下向上的路径，即经过 FPN 操作后再依次向上层特征做融合，这有助于将底层细节信息更好地传递给高层次，改善模型对小目标的检测能力
                         3. 基于**GhostPAN**结构的 Neck 结构：
                            1. 其结构思想来源于传统 PAN，但是引入了**GhostBottleNeck**，使用更少的卷积操作来生成更多特征图，减少了计算量和参数量；还引入了**深度可分离卷积层**，使用深度卷积处理每个输入通道，再使用逐点卷积(1\*1 卷积)将结果合并，同昂减少了计算量和参数量
                     4. **Prediction** 处理预测框信息、损失函数计算、输出
                        1. **Decoupled Head(解耦头)**![解耦头](picture/1.png)
                           1. 作用：生成预测框，进行一系列参数预测
                           2. 构造：
                              1. 输入特征图的尺寸由来：yolox 中巧妙地将 Backbone 结构中对原始图片的下采样操作数带入了 Pridiction 结构，由于每次下采样操作都是将原特征图边长减半的过程，Neck 中的三个输出分支分别对应 Backbone 层中的 5 次、4 次、3 次下采样操作，所以三个解耦头的输入的特征图边长分别是原始图片边长的 32 分之一、16 分之一、8 分之一，又因为**解耦头输入的特征图其实就是对原始图像进行完全、均匀划分(yolox 默认输入图像大小为 640x640，比如输入特征图尺寸为 20x20，其实就是把原始图像均匀化分成了 400 个网格单元，每个网格单元负责预测原始图片中 32x32 大小的区域)，并分别预测。**所以三个解耦头中的每个网格在原始图片中对应的大小分别为 32x32、16x16、8x8
                              2. 由 Neck 层过来的三个分支分别连接不同尺寸的解耦头(20x20、40x40、80x80)，在单个解耦头里面，又总共包含三个分支，**分别对不同参数进行独立学习**
                                 1. 其中两个在 CBL、单卷积层、sigmoid 激活函数层作用下分别进行**类别预测**(对于 N 个类别的分类，使用 N 个二分类实现)和**前景预测**(预测框中物体是否为感兴趣物体)，其输出的通道数分别等于类别数和 1
                                 2. 还有一个分支直接进行**坐标信息预测**(预测框中心点的 x、y 坐标以及预测框的长度宽度 w、h)，其生成特征图的通道数等于 4
                                 3. 三个分支分别生成大小相同，通道数不同的一系列特征图，在**concat**中进行深度上的拼接，最终变成一个通道数=(类别数+1+4)的特征图，这张特征图的尺寸表示这个解耦头一共生成了多少个预测框(一个解耦头在一个网格单元中生成一个预测框)，特征图的深度对应每个预测框的每个参数信息。
                           3. 在解耦头之后，每个输出经过 ![解耦头之后](picture/5.jpg)
                              1. **Reshape 操作**从三维张量变成二维矩阵，其中行数等于预测框数(即张量的尺寸大小)，列数等于总参数数(原张量的深度)，
                              2. **concat**操作将三个解耦头的输出矩阵拼接在一起，产生一个 8400 行的矩阵，代表三个解耦头一共产生 8400 个预测框。
                              3. **transpose**操作，将二维矩阵转置，这时每一列代表一个检测框，一共有 8400 列，每一行都代表一个参数信息
                        2. **Anchor Free**：不适用预先定义好的检测框，直接从物体特征到物体边界框进行端到端学习
                           1. 传统方式**Anchor Based**：训练过程依赖最初定义好位置和大小的预测框，之后的学习过程不断调整最初定义好的框的大小和位置以实现匹配图像中的目标，计算过程较为复杂，但是准确度更高
                           2. Anchor Free 则不需要预先定义好的预测框，直接对预测框的中心点坐标、长宽进行回归，端到端方式，识别更快
                        3. **标签分配**：在所有预测框中挑选出合适的正预测框
                           1. 初步筛选：主要有两种方式
                              1. 根据预测框中心点坐标判断：
                                 - 在 yolo 系列的标注文件中，通常包含真值框的左上角、右下角的坐标信息(x1,y1)、(x2,y2)，将其与每个预测框的中心点坐标信息(x0,y0)进行比对，如果 x1≤x0≤x2、y1≤y0≤y2,即可判断出此时预测框中心点坐标在真值框内，并将其作为初步筛选出的预测框
                              2. 根据真值框来判断：
                                 - 以真值框中心点为基准，设置边长为 5 的正方形，挑选中心点落在正方形内的所有预测框
                           2. 精细化筛选：需要经过如下几步：
                              1. **loss 函数计算**：
                                 1. **定位损失**：将每个真值框和对应的预测框之间的**iou 信息**(用来衡量两个矩形区域之间重叠程度，即交集面积比上并集面积，值在 0~1 之间，越接近 1 表示重叠度越高)通过-torch.log(就是-log 函数)转化为位置损失，即当 iou 值接近于 1 时，损失值接近于 0，当 iou 值在 0~1 之间远离 1 时，损失值迅速增大。
                                 2. **类别损失**：将每个类别的条件概率(即类别预测结果)和目标的先验概率(训练集中该类别出现的概率)做乘积，得到目标的类别分数，再经过二元交叉熵损失函数得到每个类别的损失值，然后求和得到总的类别损失值
                              2. **cost 成本计算**：
                                 1. 公式：$$c_{ij}=L_{ij}^{cls}*\lambda L_{ij}^{reg}$$
                                    1. $c_{ij}$：每个预测框最终的 cost 成本
                                    2. $L_{ij}^{cls}$：类别损失
                                    3. $L_{ij}^{reg}$：定位损失
                                    4. $\lambda$：加权系数
                              3. **SimOTA** ：为每个真值框分配最终的预测框
                                 1. **OTA 问题**：目标检测领域中是指找到一种最优的方式将检测框与真值框匹配起来，其核心在于如何有效、准确地分配预测框到真值框，以最大化整体的检测性能，为减轻计算负担、提高匹配准确性，诞生了 SimOTA
                                 2. 具体步骤：
                                    1. 确定给每个真值框分配预测框的数量
                                       1. 设置候选预测框数量：给每个真值框先选择 10 个 iou 信息最高的预测框
                                       2. cost 挑选候选预测框：将每个真值框挑选出来的 10 个预测框的 cost 值求和，并取整，最后得到的数就是给这个真值框分配的预测框数量
                                    2. 选择对应数量的预测框
                                       1. 在目前为止挑选出来的所有检测框中，将每个检测框对于每个真值框的 cost 成本都排列出来，形成一个列表，行是真值框，列是检测框，将每个真值框那一行按照其被分配的名额，挑选相应数量的 cost 成本最低的检测框，如果遇到有一个检测框同时被多个真值框选择的情况，则只将此目标框给对应 cost 值最小的真值框。
                        4. **loss 计算**：
                           1. 选择好每个真值框对应的预测框之后，就可以开始进行损失函数计算了，此处与筛选预测框时使用的损失函数不同
                              1. **定位损失**可以使用 iou_loss、giou_loss、L1 损失三种损失函数计算方式，实际使用时最后的定位损失还可能会乘以一个权重系数
                                 1. $iouloss=1-iou$
                                 2. $giouloss=1-(iou- \frac{C-A\bigcup B}{C})$
                                    1. A、B:预测框和真值框
                                    2. C: 可以包含 A、B 的最小封闭框
                              2. **类别损失**则是 BCE_loss，即二元交叉熵损失函数计算
                              3. **前景损失**是将预测框挑选之前生成的所有预测框的损失之和，同样是 BCE_loss，最后将所有预测框对应的损失求和，进行梯度下降和反向传播算法即可进行学习
               2. 推理过程的筛选
                   1. **置信度筛选**：经过训练之后，yolox 模型在进行推理时可以在目标周围生成很多预测框，得出最终的推理结果只需要保留预测结果最好的几个预测框，此处使用**置信度**来衡量一个预测框的预测结果好坏，其由每个预测框的最高类别得分乘以前景得分计算而来，在推理前可以预先设定置信度阈值，即最后只会保留高于这个阈值的检测框
                   2. **NMS 筛选**：对于保留下来的置信度较高的预测框，很显然不能全部保留，因为可能会有很多预测框几乎是重叠的，框选的是同一个目标；但是也不能只保留置信度最高的那个预测框，因为如果遇到多个检测目标排列很紧密的情况，只保留一个预测框意味着同一类别的目标将有大量被遗漏，所以 NMS 算法，即非极大值抑制（Non-Maximum Suppression）算法用于只去除同一类别中重叠度很高的一系列检测框，其原理如下：将同一类别所有保留下来的检测框按照置信度排序，取置信度最高的一个检测框为基准框，计算其与其他检测框的 IOU 值，去除掉 IOU 值大于**阈值**(超参数，由命令行输入)的所有框，保留剩下的重叠度不高的检测框，其可能是识别到了同一类别的不同对象
                   3. 综上：置信度和 NMS 的两个阈值共同对检测框进行筛选。 
           7. **YOLOV8**:
      3. 目标分割：
        1. 语义分割：不区分属于相同类别的不同实例
           1. FCN全卷积网络
           2. UNet
        2. 实例分割：区分属于相同类别的不同实例
           1. Mask RCNN
   2. 基于 Transformer：CV 领域的后来者居上，Transformer在自然语言处理领域大放异彩不禁让人想看看其能否结合 CNN 的优势并取代 CNN
      1. Vision Transformer：
      2. Swin Transformer：
4. **单幅图像超分辨率**增强领域
   1. 研究现状：
      1. 当前单幅图像超分辨率增强领域所采取的措施主要围绕两个方向：
         1. 监督学习方向：此方向使用海量数据集，发掘退化图像与高分辨率图像之间的函数映射，研究重点主要在两个领域：
            1. 增强模型，即通过提高具体使用的增强模型性能，实现对高低分辨率图像之间函数映射关系的准确拟合与效果提升，经历了卷积、生成对抗、transformer 模型、扩散模型四个阶段：
               1. SRCNN：2014年由chao 等提出，首次将卷积神经网络应用于 SR 任务，通过三层卷积神经网络实现了超分辨率增强，效果优于当时最先进的稀疏编码方法
               2. SRGAN：2017
            2. 退化模型，即针对日常生活中图片因为各种原因，如相机传感器引入噪声、网络图片传输时的压缩等导致的复杂退化过程进行建模，研究导致图像退化的更深层次的本质原因，使训练数据集高低图片对更加接近于实际生活中会出现的退化现象，避免采用经典退化模型时会出现的泛化性能不佳的问题，提高训练的效果，经历了：
               1. 
         2. 无监督学习方向：
            1. 宗旨在于发掘单张图片本身中蕴含的丰富信息，直接用测试数据本身进行训练，利用好测试数据本身的特征信息，主要经历了：
               1. ZSSR（Zero-Shot Super-Resolution）：零样本学习网络首次提出SR领域无监督卷积方法
   2. 评价体系：
      1. **PSNR**：峰值信噪比，是一种用来评价图像质量的指标，其值越大，表示图像质量越高，其计算公式如下：
         1. $$PSNR=10*log_{10}(\frac{MAX^2}{MSE})$$
            1. MAX：表示图像像素的最大值，通常为 255
            2. MSE：表示均方误差，即两张图像之间的差异，其计算公式如下：
               1. $$MSE=\frac{1}{m*n}\sum_{i=1}^{m}\sum_{j=1}^{n}(I(i,j)-K(i,j))^2$$
                  1. m、n：表示图像的长和宽
                  2. I、K：表示两张图像的像素值
      2. **SSIM**：结构相似性指标，是一种用来评价图像质量的指标，其值越大，表示图像质量越高，其计算公式如下：
         1. $$SSIM(x,y)=\frac{(2\mu_x\mu_y+C_1)(2\sigma_{xy}+C_2)}{(\mu_x^2+\mu_y^2+C_1)(\sigma_x^2+\sigma_y^2+C_2)}$$
            1. $\mu_x$、$\mu_y$：表示两张图像的均值
            2. $\sigma_x^2$、$\sigma_y^2$：表示两张图像的方差
            3. $\sigma_{xy}$：表示两张图像的协方差
            4. $C_1$、$C_2$：是两个常数，用来避免分母为 0
      3. **RMSE**：均方根误差，是一种用来评价图像质量的指标，其值越小，表示图像质量越高，其计算公式如下：
         1. $$RMSE=\sqrt{\frac{1}{m*n}\sum_{i=1}^{m}\sum_{j=1}^{n}(I(i,j)-K(i,j))^2}$$
            1. m、n：表示图像的长和宽
            2. I、K：表示两张图像的像素值
      4. **MOS**：主观评价指标，是一种用来评价图像质量的指标，其值越高，表示图像质量越高，其计算公式如下：
         1. $$MOS=\frac{1}{N}\sum_{i=1}^{N}Q_i$$
            1. N：表示评价者的数量
            2. $Q_i$：表示第 i 个评价者对图像质量的评价
   3. 具体方法：
      1. 基于 GAN 模型：
         1. **初识 SRGAN**（超分辨率增强网络）
         2. **初识 ESRGAN**
      2. 基于扩散模型：
         1. **初识 DDPM**

---
## 理论原理

---
## 总结与展望
1. 关于我为什么要写这一篇浅思：
   - 最开始想要写这个的原因毫无疑问就是为了个人学习深度学习知识时的总结，目的是搭建这一领域体系化的知识储备。随着个人对于这一领域的了解深入，不由得，或者说必然地产生了一种关于**未来将何去何从** 的思考，关于人类的未来将何去何从，深度学习的未来将何去何从，我个人的未来又将何去何从。于是我有了一种来自内心的使命感，开始多频次、多方面的思考，我意识到，**保持想象力、保持思考**，或许是未来人类最重要的，亦或许是最稀缺的力量。对于我来说，我有记录下自己思考行为的使命，并且我深以为自己所写的一切于人类群体来说是有利的。
2. 关于人类未来将何去何从：
   - 关于人类此行的目的： 
   - 人类自身能力观与工具观：我越来越相信自己的一个观点：**知识储备**、**思维能力**、**行动力**永远是人类个体核心能力的唯三衡量标准，人类对任意工具的使用态度应该是：使用好这个工具，使我自身得到上述三种能力的提升，而不是将工具本身当作了我个人能力的一部分。摆明这两点之后，我们就能在变幻莫测，充斥着各种牛鬼蛇神、好坏技术鱼目混珠的当下，做到持续稳健的、始终目标明确的个人能力提升，而不是被路边时不时冒出的技术诱惑亦或是威胁带偏了原本的前进方向。
3. 关于深度学习未来将何去何从：
   - 深度神经网络的必要性与主战场：一切形式神经网络的主战场应该是尚未或不可能形成理论公式的混沌领域，对于已形成理论公式且对数据精度敏感的领域，端到端直接拟合的方式加速运算或只是顺带解决
4. 关于我未来将何去何从： 